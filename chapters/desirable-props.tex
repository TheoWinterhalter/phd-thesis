% \setchapterpreamble[u]{\margintoc}
\chapter{Desirable properties of type theories}
\labch{desirable-props}

To compare different type theories there are several measures we can use in
form of usual or desirable properties that they might satisfy or not.
After a brief presentation of the main ones I will summarise which of the
theories of \nrefch{flavours} has which properties in a table.

\section{Properties}

\subsection{Weakening and substitutivity}
\labsubsec{weak-subst}

Variables and binders are essential to type theory and as such we have to treat
them with care, in particular we want our theories to be \emph{compositional}
meaning that different blocks that make sense can be assembled into something
that still makes sense.
This is embodied in the two following properties.

\begin{definition}[Weakening]
  A type theory enjoys weakening when for any \(\Ga, \Xi \vdash t : A\) and
  \(\vdash \Ga, \Delta\) we have \(\Ga, \Delta, \Xi \vdash t : A\).
\end{definition}
\marginnote[-1.2cm]{
  Note that in more generality you might have to rename variables when
  weakening, so for this we usually introduce a \emph{lifting} operator
  \(\lift{}{}\) such that we have
  \(\Ga, \Delta, \Xi \vdash \lift{n}{k}\ t : \lift{n}{k}\ A\)
  where \(n = |\Delta|\) and \(k = |\Xi|\).
}

Weakening means that you can plug a term into a larger context.

Susbstitutions are the way to instantiate the variables that are bound.
This happens for instance after a \(\beta\)-reduction.
\reminder[-0.9cm]{\(\beta\)-reduction}{
  \[
    (\lambda (x:A). t)\ u \red_\beta t[x \sto u]
  \]
}
Substitutions are typed using two contexts: \(\sigma : \Ga \to \D\) basically
states that \(\sigma\) maps variables of \(\D\) to terms typed in \(\Ga\).
\begin{mathpar}
  \infer
    {\forall (x : A) \in \D,\ \Ga \vdash \sigma(x) : A\sigma}
    {\sigma : \Ga \to \D}
\end{mathpar}
This is sometimes written \(\Ga \vdash \sigma : \D\) instead, and typing
definitons vary a little depending on the definition of substitution but this
is the basic idea.

\begin{definition}[Substitutivity]
  A type theory is substitutive when for any \(\D \vdash t : A\)
  and any substitution \(\sigma : \Ga \to \D\), we have
  \(\Ga \vdash t\sigma : A\sigma\).
\end{definition}

More often than not, weakening and substitutivity also hold for reduction and
conversion.

\subsection{Inversion of typing}

Inversion of typing is not really a measure as it is always present in some way.
It is nonetheless a very useful property to state when reasoning on a type
theory.
It is saying than when we have \(\Ga \vdash t : A\), by analysing the shape of
\(t\) we can get information on \(A\) (and sometimes even \(\Ga\)).

\reminder[-0.6cm]{Application rule}{
  \[
    \infer
      {
        \Ga \vdash \Pi (x:A).\ B : s \\
        \Ga \vdash t : \Pi (x:A).\ B \\
        \Ga \vdash u : A
      }
      {\Ga \vdash t\ u : B[x \sto u]}
  \]
}
For instance, if we have \(\Ga \vdash t\ u : T\), then by inversion of typing
we know that there must exist \(A\) and \(B\) such that
\begin{mathpar}
  \Ga \vdash \Pi (x:A).\ B : s

  \Ga \vdash t : \Pi (x:A).\ B

  \Ga \vdash u : A

  \Ga \vdash T \equiv B[x \sto u]
\end{mathpar}

This can be proved by seeing that only two typing rules can be concluded with
\(\Ga \vdash t\ u : T\): the application rule and the conversion rule. The
result follows from a simple induction.

\marginnote[0.1cm]{
  Sometimes it will be talking about cumulativity \(\cumul\) instead of
  conversion \(\equiv\): in that case we would have
  \(\Ga \vdash B[x \sto u] \cumul T\) (we have to apply the application rule
  first and then possibly several time the cumulativity rule).
}
Now, it will not always be stated this way depending on the premises of the
application rule, but also depending on the presence or not of a conversion
rule. In the case of \acrshort{WTT} for instance, there is no conversion so
instead of \(\Ga \vdash T \equiv B[x \sto u]\) we will have syntactic equality
\(T =_{\alpha} B[x \sto u]\).

You usually prove inversion of typing for every term constructor, but I will not
do it here.

\subsection{Validity}

The term \emph{validity} might be a bit overloaded, and maybe not the norm
when it comes to type theory, but I will use it to be consistent with the
notion for \Coq.
This property states that the type on the right-hand side of the colon is indeed
a type.

\begin{definition}[Validity]
  A type theory enjoys validity when from \(\Ga \vdash t : A\) one can deduce
  \(\Ga \vdash A\) (\ie \(\Ga \vdash A : s\) for some sort \(s\)).
\end{definition}

Depending on the theory, we can often prove a similar property regarding
contexts: namely that \(\Ga \vdash t : A\) implies that \(\Ga\) is well-formed
(\(\vdash \Ga\)). Having this property mainly depends on whether the typing
rules of things like sorts and variables ask for the context to be well-formed.
%
\begin{mathpar}
  \infer
    {(x : A) \in \Ga}
    {\Ga \vdash x : A}
  %

  \text{vs}

  \infer
    {
      \vdash \Ga \\
      (x : A) \in \Ga
    }
    {\Ga \vdash x : A}
  %
\end{mathpar}
%
In a theory which does not have this requirement / property, many lemmata will
only apply assuming the contexts involved are well-formed.
The difference between presentations like this will be studied in
\nrefch{formalisation}.

\subsection{Unique / principal typing}

Unique typing is a property saying that each term (given a context) has only one
type up to conversion.

\begin{definition}[Unique typing]
  A type theory enjoys unique typing when
  \(\Ga \vdash t : A\) and \(\Ga \vdash t : B\) imply \(\Ga \vdash A \equiv B\).
\end{definition}

\marginnote[0.5cm]{
  We will talk more in depth about Curry-style terms in \nrefch{formalisation}.
}
This usually means that the term is carrying enough information to recover
its type. If one were to use Curry-style terms like
\(\lambda x.\ x\) then this property cannot hold: indeed
\(\vdash \lambda x.\ x : \unit \to \unit\) and
\(\vdash \lambda x.\ x : \bool \to \bool\) both hold and the two arrow types
are not related.

This property can be broken for other reasons however: the presence of subtyping
(typically cumulativity). In such a case, unique typing can be relaxed to
principal typing.

\begin{definition}[(Weak) principal typing]
  A type theory enjoys principal typing (in the weaker sense) when
  \(\Ga \vdash t : A\) and \(\Ga \vdash t : B\) imply \(\Ga \vdash t : C\) with
  \(\Ga \vdash C \cumul A\) and \(\Ga \vdash C \cumul B\).
\end{definition}

It might be perhaps more often understood in a stronger sense.

\begin{definition}[(Strong) principal typing]
  A type theory enjoys principal typing (in the stronger sense) when for every
  well typed term \(t\) in \(\Ga\), there exists a type \(P\) such that
  \(\Ga \vdash t : P\) and that whenever \(\Ga \vdash t : A\) we have
  \(\Ga \vdash P \cumul A\).
  \(P\) is called a principal type of \(t\) (in \(\Ga\)).
\end{definition}

The idea is that the principal type is the most general type that can be given
to a term.

\subsection{Properties of reduction}

When the type theory features reduction, we also want it to satisfy some
requirements, aside that reduction behaves in a compositional way as I already
explained in \arefsubsec{weak-subst}.

First are basic properties of rewriting systems\sidenote{I will not go into details
about what they are and it's not necessary to know about them to understand any
of this.}: confluence and termination.

\sidedef[-0.4cm]{}{
  The transitive reflexive closure of reduction, written \(\reds\),
  is defined (inductively) by the rules
  \[
    \infer
      { }
      {t \reds t}
    %
  \]
  \[
    \infer
      {
        t \red u \\
        u \reds v
      }
      {t \reds v}
    %
  \]
}
\begin{definition}[Confluence]
  The reduction relation \(\red\) is confluent if for every \(t\) such that
  \(t \reds u\) and \(t \reds v\) there exists \(w\) such that \(u \reds w\)
  and \(v \reds w\).
\end{definition}

Confluence is often summarised with the following diagram.

\begin{center}
  \begin{tikzpicture}
    \node (t) { \(t\) } ;
    \node (dummy) [below of = t] { } ;
    \node (u) [left of = dummy] { \(u\) } ;
    \node (v) [right of = dummy] { \(v\) } ;
    \node (w) [below of = dummy] { \(\exists w\) } ;
    % \draw[tred] (t) to (u) ;
    % \draw[tred] (t) to (v) ;
    % \draw[tred, dashed] (u) to (w) ;
    % \draw[tred, dashed] (v) to (w) ;
    \path (t) edge[to*, tred] (u) ;
    \path (t) edge[to*, tred] (v) ;
    \path (u) edge[*to, tred, dashed] (w) ;
    \path (v) edge[*to, tred, dashed] (w) ;
  \end{tikzpicture}
\end{center}

\begin{definition}[Weak normalisation]
  Weak normalisation of reduction means that for every well-typed term \(t\)
  there exists a term \(n\) such that \(t \reds n \not\red\).
  \(n\) is called a \emph{normal form} of \(t\).
\end{definition}

A normal form is a term that cannot reduce any further as illustrated by the
\(n \not\red\) notation.

\begin{definition}[Strong normalisation]
  Strong normalisation, or termination, of reduction means that for every
  well-typed term \(t\), there is no infinite reduction sequence starting from
  \(t\).
\end{definition}

When a system is confluent and terminating, there exists exactly one normal form
for each well-typed term, we can thus talk about \emph{the} normal form of a
term.

These properties are related to typing in that they require the term to be
well-typed in order to be applicable. That's because it's too easy to break
termination with non-sensical terms.
There is however a reduction property that is much more linked to typing:
subject reduction, sometimes called type safety or type preservation.

\begin{definition}[Subject reduction]
  A type theory enjoys subject reduction when for every \(\Ga \vdash t : A\)
  and \(t \red u\), we also have \(\Ga \vdash u : A\).
\end{definition}

This means simplifying a proof does not break its status of proof. This is a
very sensible property to have in a programming language or a proof assistant.
Its absence is usually a sign that something is very wrong with the considered
system: if evaluation might break things, why have evaluation at all?

\subsection{Injectivity of \(\Pi\)-types}

Another property slightly related to confluence and subject reduction is
the injectivity of \(\Pi\)-types. It is part of the more general notion of
injectivity of constructors and non-confusion of type constructors.

For \(\Pi\)-types, injectivity means that whenever
\[
  \Pi (x:A).B \equiv \Pi (x:A').B'
\]
then we have both \(A \equiv A'\) and \(B \equiv B'\).

This property is usually proven using confluence of reduction (when it makes
sense) so that \(\Pi (x:A).B \equiv \Pi (x:A').B'\) is equivalent to both types
reducing to the same term. Since the \(\Pi\) type constructor will never
disappear from reduction, it necessarily means that \(A\) and \(A'\) reduce to
the same term, hence are convertible (and the same holds for the codomains).

Injectivity of \(\Pi\)-types is crucial in proving that \(\beta\)-reduction is
type-preserving, one of the key elements to the proof of subject reduction.

Injectivity of constructors states that for instance
\(\natsucc\ n \equiv \natsucc\ m\) implies \(n \equiv m\) while non-confusion
says that \(\zero \not\equiv \natsucc\ n\) or \(\Type \not\equiv A \to B\).
Those are useful to achieve consistency which we will see later.

\subsection{Canonicity}

Canonicity is a way of saying that, for instance, booleans \emph{really} are
booleans \ie they are either \(\ttrue\) or \(\ffalse\).
It is an important property, especially when seen through the constructivism
prism.
When expressed for \(\Sigma\)-types, this corresponds to the so-called
\emph{witness property}: a proof of \(\Sigma (x:A).\ P\ x\) (in the empty
context, so without assumption) is necessarily of the form \((t;p)\)
with \(t : A\) and \(p : P\ t\).

\begin{definition}[Canonicity]
  A type theory enjoys canonicity when \(\vdash t : \bool\) implies that
  either \(t \equiv \ttrue\) or \(t \equiv \ffalse\).
  More generally, every term of an inductive type is convertible to a
  construction of this type.
\end{definition}

This is usually true in a much stronger and useful sense:

\begin{definition}[Computational canonicity]
  Computational canonicity corresponds to the fact that whenever
  \(\vdash t : \bool\), then either \(t \reds \ttrue\) or
  \(t \reds \ffalse\).
  More generally, every term of an inductive type reduces to a construction
  of this type.
\end{definition}

So computational canonicity ensures that whenever you prove that there exists
some \(t\) such that \(P\ t\), it is possible to evaluate the proof to extract
the \(t\) in question.

\subsection{Decidability of type-checking}

A property is called \emph{decidable} when there exists an algorithm that
returns \(\ttrue\) whenever it holds, and \(\ffalse\) otherwise.
Decidability of type-checking thus means the existence of a sound and complete
type-checker:

\begin{definition}[Decidability of type-checking]
  Type checking is decidable for a type theory if there exists an algorithm
  such that, when given a context \(\Ga\), a term \(t\) and a type \(A\),
  returns \(\ttrue\) when there is a derivation of \(\Ga \vdash t : A\)
  and \(\ffalse\) when there is not.
\end{definition}

There are variants of this of course, sometimes it will only work when we
already know that \(\vdash \Ga\) and \(\Ga \vdash A\).

Sometimes we have a stronger property, as is the case for \Coq, that is
decidability of inference:
there is an algorithm taking \(\Ga\) and \(t\) and which returns some \(A\)
such that \(\Ga \vdash t : A\) or an error stating that \(t\) is ill-typed.

Decidability of type-checking is an important property because it crystalises
the fact that a term is indeed a \emph{proof}, it is a good enough certificate
that people can check independently.
However, in a system that does not feature decidable type-checking, you can still
provide certificates: for one you could simply store the full-derivation as a
proof; it is however possible to translate the proof to another system with
decidable checking, like I will present in \arefpart{elim-reflection}.

\subsection{Consistency}

To be able to use a type theory as a logic, it needs to be consistent.
Consistency means that not all types are provable, or equivalently that
the empty type is uninhabited.
\marginnote[-0.4cm]{
  See \nrefch{usual-defs} for definition(s) of the empty type \(\bot\).
}

\begin{definition}[Consistency]
  A type theory is said to be consistent when there is no term \(t\) such that
  \(\vdash t : \bot\).
\end{definition}

This does not prevent you from having proofs of \(\bot\) in inconsistent
contexts.

Having canonicity in the theory is a good way to deduce consistency.
Indeed, if there is a proof of \(\bot\) in the empty context, there must
one which is a constructor, since there are no constructors for \(\bot\)
it's not possible.

It's worth noting that inconsistent type theories can still be of interest.
For instance if you're interested in having effects in your type theory,
though you might want to be able to know which terms might use effects leading
to inconsistencies and use only \emph{pure} terms to prove
things~\sidecite{pedrot:hal-02189128,pedrot:hal-02383109}.
This allows for proofs on impure programs.

\section{Summarising table}

I will now try to summarise which theory enjoys which property in a table.
Weakening, substitution and validity always hold in theories that I consider and
inversion of typing always holds in some way or another so I will not put them
in the table.

I will separate the theories in four groups sharing properties.
\begin{enumerate}[label=(\Alph*)]
  \item \label{item:coq} \Coq/\acrshort{PCUIC}
  \item \label{item:agda} \Agda/\acrshort{MLTT}, \acrshort{CubicalTT}
  \item \label{item:ett} \acrshort{ETT}
  \item \label{item:wtt} \acrshort{WTT}
\end{enumerate}
2-level variants of the theory should enjoy the same properties as their 1-level
counterpart: \acrshort{HTS} goes in \ref{item:ett} while \acrshort{2TT} goes
in \ref{item:agda}.
\acrshort{HoTT} can also be considered a variant of a type theory, and should be
placed in either \ref{item:coq} or \ref{item:agda} depending on whether it
features cumulativity or not.
Likewise, \acrshort{ITT} could go in either \ref{item:coq} or \ref{item:agda}.

\marginnote[1.3cm]{
  I write -- for properties that do not apply like properties on reduction
  for any theory without.
}
\begingroup

  \centering
  \rowcolors{1}{SkyBlue!10!White}{}
  \def\arraystretch{1.3}
  \begin{tabular}{l|c|c|c|c|}
    \cline{2-5}
    & \ref{item:coq} & \ref{item:agda} & \ref{item:ett} & \ref{item:wtt} \\
    \hline
    \multicolumn{1}{ |l|  }{Unique (U) / Principal type (P)} &
    P & U & U & U \\
    \hline
    \multicolumn{1}{ |l|  }{Confluence} &
    yes & yes & -- & -- \\
    \hline
    \multicolumn{1}{ |l|  }{Normalisation} &
    yes & yes & -- & -- \\
    \hline
    \multicolumn{1}{ |l|  }{Subject reduction} &
    yes & yes & -- & -- \\
    \hline
    \multicolumn{1}{ |l|  }{Injectivity of \(\Pi\)-types} &
    yes & yes & no & no \\
    \hline
    \multicolumn{1}{ |l|  }{Computational / regular canonicity} &
    comp & comp & reg & no \\
    \hline
    \multicolumn{1}{ |l|  }{Decidability of type-checking} &
    yes & yes & no & yes \\
    \hline
    \multicolumn{1}{ |l|  }{Consistency} &
    yes & yes & yes & yes \\
    \hline
  \end{tabular}

\endgroup