% \setchapterpreamble[u]{\margintoc}
\chapter{Flavours of type theory}
\labch{flavours}

Type theory comes in many different flavours and shapes, different formulations
and properties. I will not try to be exhaustive but I will try to cover the
main kind of dependent type theories I have encountered.
I will not attempt to define properly the notion of \emph{type theory},
there is work on this~\misref{} but it is still a bit early to grasp the
concept fully.

\section{Computation and type theory}

The first prism in which to see type theory through can be that of computation.
Indeed, not all type theories feature it to the same extent. Though for some
people in computation resides the essence of type theory, it is still worth
it to investigate theories where conversion is defined differently.

\subsection{Intensional Type Theory}
\labsubsec{pts-itt}

\acrfull{ITT} is the name given to a wide range of type theories actually.
Those could be described in the setting of \acrlongpl{PTS}.
The theories behind the proof assistans \Coq and \Agda---respectively
\acrfull{PCUIC} and \acrfull{MLTT}\sidenote{Note that \acrshort{MLTT} also
have various forms.}---are variants of \acrshort{ITT}.

A \acrshort{PTS} is a pretty basic type theory, it is parametrised by a
collection of sorts \cS, with so called \emph{rules}
(\Rl) and \emph{axioms} (\Ax).
Its syntax features \(\lambda\)-abstractions, applications, variables,
\(\Pi\)-types and sorts.
%
\[
  \begin{array}{lrl}
    s &\in& \mathcal{S} \\
    T,A,B,t,u,v &\bnf& x \bnfor \lambda (x:A). t \bnfor t\ u
    \bnfor \Pi (x : A). B \bnfor s \\
    \Ga, \D &\bnf& \ctxempty \bnfor \Ga, x:A
  \end{array}
\]

Their computational behaviour is defined by a reduction relation (\(\red\))
which is the contextual closure of the \(\beta\)-reduction.
\[
  (\lambda (x:A). t)\ u \red_\beta t[x \sto u]
\]
\marginnote[-0.9cm]{
  For instance
  \(\lambda (x : A). (\lambda (y : B) y x)\ t \red \lambda (x : A). t x\)
}

The typing rules involve the rules and axioms we mentioned earlier.
%
\begin{mathpar}
  \infer
    {(s,s') \in \Ax}
    {\isterm{\Ga}{s}{s'}}
  %

  \infer
    {
      \isterm{\Ga}{A}{s_1} \\
      \isterm{\Ga, x : A}{B}{s_2} \\
      (s_1, s_2, s_3) \in \Rl
    }
    {\isterm{\Ga}{\Pi (x:A). B}{s_3}}
  %

  \infer
    {(x : A) \in \Ga}
    {\isterm{\Ga}{x}{A}}
  %

  \infer
    {
      \isterm{\Ga, x:A}{t}{B} \\
      \isterm{\Ga}{\Pi (x:A).B}{s}
    }
    {\isterm{\Ga}{\lambda (x:A).t}{\Pi (x:A).B}}
  %

  \infer
    {
      \isterm{\Ga}{t}{\Pi (x:A). B} \\
      \isterm{\Ga}{u}{A}
    }
    {\isterm{\Ga}{t\ u}{B[x \sto u]}}
  %

  \infer
    {
      \isterm{\Ga}{t}{A} \\
      A \equiv B \\
      \isterm{\Ga}{B}{s}
    }
    {\isterm{\Ga}{t}{B}}
  %
\end{mathpar}
%
Axioms determine typing of sorts, and rules what dependent products are allowed.
The last rule is the conversion rule, it is the rule that involves computation:
basically you can exchange two computationally equal types in a typing
judgement. The \(\isterm{\Ga}{B}{s}\) bit is to make sure the type we want
to substitute still makes sense.
In this case, conversion (\(\equiv\)) is defined as the reflexivie,
symmetric, transitive closure of reduction.
\marginnote[-0.4cm]{
  \(t \equiv u\) is defined as \(t \mathop{(\redl . \red)^\star} u\)
}

When talking about \acrshort{ITT} we usually mean an extension of this with
more concepts like some base types~\misref{} and computation rules on their
eliminators (pattern-matching). The conversion rule is also not always strictly
derived from the reduction alone, it often includes \(\eta\)-rules, the most
common being \(\eta\)-expansion of functions.
\[
  f \equiv_\eta \lambda (x:A). f\ x
\]
For it to make sense expansion has to be limited to functions which requires
type information\sidenote{Also, the \(A\)---domain of the function---has to
be sumrised somehow.}, this is why is certain contexts---like \Agda---the
conversion is also typed.
The relation between typed and untyped conversion has been explored at several
occasions~\misref.
\Coq manages to verify \(\eta\)-conversion for functions and records without
relying on a typed-conversion as we will see later~\misref.
\marginnote[-0.5cm]{
  For instance, \(\eta\) for pairs is \(p \equiv (p.1, p.2)\) where
  \(p.1\) and \(p.2\) are the first and second projections of \(p\).
}

\subsection{Extensional Type Theory}

\acrfull{ETT} is an extension of \acrshort{ITT} where conversion is extended
to capture all provable equalities, this principle is called \emph{reflection
(of equality)}.
This of course implies that the considered \acrshort{ITT} is equipped with
an equality type.

\begin{definition}{Reflection Rule}
  \labdef{reflection}
  \begin{mathpar}
    \infer[]
      {\xisterm{\Ga}{e}{\Eq{A}{u}{v}}}
      {\xeqterm{\Ga}{u}{v}{A}}
    %
  \end{mathpar}
\end{definition}

As you can see, this time I opted for a typed conversion, I think it makes more
sense since the conversion is more semantical than syntactical.
Also, you can note the little \(\exmark\) subscript, its purpose is to mark
the judgement as beeing \emph{ex}tensional.
\Andromeda and \NuPRL implement variants of \acrlongpl{ETT}~\misref.
To see its usefulness, we're going to look at the definition of reversal of
vectors in \Coq, using an accumulator for the definiton to be tail-recursive.
%
\begin{minted}{coq}
Definition vrev {A n m} (v : vec A n) (acc : vec A m)
  : vec A (n + m) :=
  match v with
  | vnil => acc
  | vcons a n v => vrev v (vcons a m acc)
  end.
\end{minted}
%
The recursive call of \mintinline{coq}{vrev} returns a vector of length
\mintinline{coq}|n + S m| where the context expects one of length
\mintinline{coq}|S n + m|. In \acrshort{ITT} and \Coq, thesec types are not
convertible, and thus the definition isn't accepted, even though it feels like
it is the right definition. \acrshort{ETT} solves this problem by exploiting
the fact that \mintinline{coq}|n + S m = S n + m| is provable.
You can still define it in \Coq, but you have to explicitely transport along
the abovementioned equality which can result in some problems while reasoning
on the resulting function and inconveniences overall.
\todo{Perhaps give concrete defs for ETT/ITT/WTT so that we can rely on them
in the second part.}

\acrshort{ETT} isn't the ultimate solution however and suffers from many
drawbacks the main of which being that type-checking is not decidable as we
shall see later~\misref. We will also explore the relation between
\acrshort{ETT} and \acrshort{ITT}~\misref.

\subsection{Weak Type Theory}
\labsubsec{wtt}

A \acrfull{WTT} is on the other end of the spectrum: instead of extending
conversion with everything that can be proven equal, conversion is removed
altogether. Computation (like \(\beta\)-reduction) is now handled by
propositional equality alone, and conversion of types is done using transports
of said equality.

This time it's a bit hard to advertise it for practical use in a proof
assistant, it's nonetheless interesting. For one, its meta-theory is that much
simpler, an even more attractive fact once combined with a translation from
\acrshort{ITT} (or \acrshort{ETT}) to \acrshort{WTT} as is the object of
\refpart{elim-reflection}.
Another point worth mentioning is that it really crystallises the notion that
proofs are really just terms and do not require extra machinery to make sure
they are indeed proofs (even when conversion is decidable, it might takes
eons before you get this knowlegde)~\misref.

One might also be tempted to call it minimal, but in order to simulate the
congruence aspect of conversion, we have to extend the theory with principles
to allow equalities under binders, and this has to be done for each binder
(once for \(\lambda\)-abstractions---the usual functional extensionality---and
once for \(\Pi\)-types---much less standard---at least).

\section{Focus on the theory behind \Coq}

\Coq is originally based on the \acrfull{CoC}, or the \acrfull{CIC}, though it
is nowadays rather called the \acrfull{PCUIC}.
It is a variant of \acrshort{ITT} but as the name suggests, it has several
extra features, hinted at by the words \emph{cumulative}, \emph{inductive}
and \emph{predicative}.

\subsection{Universes in \Coq}

\Coq features a \emph{predicative} hierarchy of universes
\((\Type_i)_{i \in \mathbb{N}}\) such that \(\Type_i : \Type_j\) for any
\(i < j\). The presence of several universes included in one another is not
there for fun, it is there to circumvent Russel's paradox~\misref{} which
shows it is inconsistent to have \(\Type : \Type\).
The \Coq user however doesn't usually has to deal with those and
instead rely on the so-called \emph{typical ambiguity}~\misref{}: in the \Coq
proof assistant one will simply write \(\Type\) and \Coq will infer constraints
to know whether it is possible to appoint each occurrence of \(\Type\) a
\emph{level}, \ie a natural number, such that the universes are used
consistently.

Alongside this hierarchy comes another universe, \(\Prop\) which is the universe
of propositions. This universe is \emph{impredicative}.
Impredicativity means that the definition of an object can quantify over the
object itself. In the case of \(\Prop\) it comes from the fact that a
proposition (\ie a type in \(\Prop\)) can quantify over propositions: \eg
\(\forall (P : \Prop).\ P\) is still a proposition.
\marginnote[-0.5cm]{
  We write \(\forall (P : \Prop).\ P : \Prop\).
  Note that this type is actually the empty type or false proposition so it's
  reassuring that it \emph{is} a proposition.
}
Actually impredicativity of \(\Prop\) is a bit stronger as it accepts \emph{any}
quantification, so that \(\forall (n : \mathbb{N}).\ n = n\) is also a
proposition for instance.
\(\Prop\) however is of type \(\Type_i\) for any \(i\).

Recently, a new universe of propositions has been introduced~\misref:
\(\SProp\). This time it is a universe of \emph{strict} propositions in the
sense that any two proofs of the same proposition are considered to be
convertible.
\marginnote[-0.7cm]{
  For \(P : \SProp\) and \(p_1 : P\) and \(p_2 : P\) then \(p_1 \equiv p_2\).
}
In other words, there is no computational content to proofs of strict
propositions, and as such proofs are \emph{irrelevant}, only there mere
existence matters.
Although this addition is a really interesting subject, it goes a bit beyond
the scope of this thesis, in particular I do not consider it in my
formalisations (for now).

When I introduced the typing rules for \(\Prop\) and \(\Type\) I showed that
each universe can be typed in several other universes (actually in each case
there are an infinite number of possiblities). The reality is even more
intricate than that and it has to do with \emph{cumulative} part of the name.
\Coq features a notion of subtyping that is limited to universes and that is
called \emph{cumulativity}. In essence it says that \(\Type_i \le \Type_j\)
whenever \(i \le j\), that is that bigger universes contain the smaller
universes. Cumulativity is given by the following rules.
\begin{mathpar}
  \infer*[right=(\(i \le j\)), vcenter]
    { }
    {\Ga \vdash \Type_i \le \Type_j}
  %

  \infer
    { }
    {\Ga \vdash \Prop \le \Type_i}
  %

  \infer
    {
      \Ga \vdash A \equiv A' \\
      \Ga, x : A \vdash B \le B'
    }
    {\Ga \vdash \Pi\ (x : A).\ B \le \Pi\ (x : A').\ B'}
  %

  \infer
    {
      \Ga \vdash t : A \\
      \Ga \vdash A \le B \\
      \Ga \vdash B
    }
    {\Ga \vdash t : B}
  %
\end{mathpar}
\marginnote[-1.5cm]{
  Notice how the usual conversion rule is replaced by a cumulativity rule.
}
This convenience allows the user to forget as much as possible about universes.


Finally there is another point regarding universes that isn't hinted at in the
name: \emph{polymorphism}. This feature introduced by~\misref{} is complementary
to cumulativity and allows to consider definitions that quantify over universe
levels (the \(i\) in \(\Type_i\)).
For instance, it allows to write a truly polymorphic identity function
\[
  \mathsf{id}@\{i\} \coloneqq \lambda (A : \Type_i)\ (x : A).\ x
\]
Here, the \(@\{i\}\) is to bind level \(i\) in the expression. Notice that it's
attached to the constant definition and not on the right-hand side; that's
because universe levels are only quantified in a prenex-style, meaning you
must quantify over \emph{all} universe levels before introducing other
variables. In particular there is no type of polymorphic
identities\sidenote{Although there is just the one.}.

One might notice that currently, universe polymorphism only talks about
\(\Type\) and does not make mention of \(\Prop\). This is a shortcoming that
could be fixed using also \emph{sort polymorphism} but at the time of writing
of this document, another technology is used in place:
\emph{template polymorphism}. It is a heuristic orthogonal to universe
polymorphism to define constants both at the \(\Type\)-level and at the
\(\Prop\)-level at the same time. However, this seems to be the source of many
bugs and should be removed from \Coq's kernel at some point in the relatively
near future.

\subsection{Inductive types}

\todo{Refer to usual-defs and talk about cumulative inductive briefly.}

\section{Equality in type theories}

\todo{Re-present the inductive eq then HoTT, talk about alternatives like OTT
and cubical, then present two-level type theories and HTS. Also point towards
quotients, QIT}