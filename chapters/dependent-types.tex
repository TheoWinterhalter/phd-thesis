% \setchapterpreamble[u]{\margintoc}
\chapter{Dependent types}
\labch{dependent-types}

The idea behind dependent types is that they now can \emph{depend} on terms,
\ie terms can appear in types. This is very interesting because we can talk
about things like \(P\ n\) for a property on a natural number \(n\),
equality \(x = y\), and with it we can support quantifiers.

It is not only useful on the logical side, but also on the programming language
side: with it programs can be given much more precise types.
For instance, you might want to specify that the division operator does not
accept \(0\) for the denominator, or that the operation returning the tail of
list only applies to non-empty lists.
Finally, we can take advantage of both and write \emph{proofs} about the
programs we wrote, using the very same language.

\section{A minimal dependent type theory}

Let me describe a very basic type theory with dependent types.

\paradot{\(\Pi\)-types}

The simplest way to get dependent types is to extend the \acrshort{STL}---which
only features arrow or function types---with dependent function types or
\(\Pi\)-types.
\[
  \infer
    {\Ga, x :A \vdash t : B}
    {\Ga \vdash \lambda (x:A).t : \Pi (x:A).\ B}
  %
\]
As you can see, we keep the \(\lambda\)-terms of earlier but now they represent
dependent functions. Now, not only \(t\) can mention \(x\), but \(B\) also.
For instance we can write the polymorphic identity function as follows
\marginnote[0.7cm]{
  I will explain later what the \(\Type\) here means, but it should be
  intuitive: I am taking a \emph{type} \(A\) as argument and then an element
  \(a\) of that type.
}
\[
  \lambda (A : \Type).\ \lambda (a : A).\ a
\]
and it has type
\[
  \Pi (A : \Type).\ \Pi (a : A).\ A
\]
which will write more concisely as
\[
  \lambda\ (A : \Type)\ (a : A).\ a
  : \Pi\ (A : \Type)\ (a : A).\ A
\]
or even as
\marginnote[0.5cm]{
  \(A \to B\) is no longer a definition, but a notation for the dependent
  function type which is not actually dependent \(\Pi (\_ : A).\ B\).
}
\[
  \lambda\ (A : \Type)\ (a : A).\ a
  : \Pi\ (A : \Type).\ A \to A
\]
since \(a\) is not mentioned.
Now we should be able to see the dependency on \(A\).
One can argue that \(A\) is a \emph{type} and not a term, but in this setting,
types are just a special kind of terms that happen to be of type \(\Type\).

If we have some \(B : \Type\) we might want to apply our polymorphic identity
function to it to get the identity function on \(B\), \ie
\[
  \lambda (a:B).\ a : B \to B
\]

For this we have to rely on substitutions again, not only in the terms after
\(\beta\)-reduction, but also in types.
This can be seen in the application rule:
\[
  \infer
    {
      \Ga \vdash u : \Pi (x:A).\ B \\
      \Ga \vdash v : A
    }
    {\Ga \vdash u\ v : B[x \sto v]}
  %
\]
Once again it is pretty similar to the application rule of simple type theory
except we have to account for the dependency. In our example---writing \(\cid\)
for the polymorphic identity function---we have
\marginnote[0.7cm]{
  What happens is the type of the application is
  \[
    (A \to A)[A \sto B] = B \to B
  \]
}
\[
  \infer
    {
      \Ga \vdash \cid : \Pi (A:\Type).\ A \to A \\
      \Ga \vdash B : \Type
    }
    {\Ga \vdash \cid\ B : B \to B}
  %
\]

\paradot{Universes}

In the example above there is the peculiar type \(\Type\).
This can be thought of as the type of types. If you know about Russel's paradox
stating that there can be no set of all sets, you might be skeptical and indeed
having \(\Type\) of type \(\Type\) is inconsistent.
We will address this in more details in \arefsubsec{coq-univ} in
\nrefch{flavours}.
In this case, \(\Type\) will be a special type---which we call universe as it
is inhabited solely by types---that does not have a type itself.
Having it is mainly to allow for quantifying over types, but we could also of
course define some base types like the natural numbers \(\nat\) and put it in
\[
  \nat : \Type
\]
We will see more example of types in \nrefch{usual-defs}. For now we only have
\(\Pi\)-types in them:
\[
  \infer
    {
      \Ga \vdash A : \Type \\
      \Ga, x : A \vdash B : \Type
    }
    {\Ga \vdash \Pi (x:A).\ B : \Type}
  %
\]
Here we evidence the fact \(B\) is indeed dependent over \(x : A\).
This kind of universe is called a Russel universe, and there are also Tarski
universes, the difference will be explained in \arefsubsec{univ-and-types}
of \nrefch{formalisation}.

I will now put the syntax and the rules together for clarity, at the risk of
repeating myself.
\[
  \begin{array}{rcl}
    A, B, t, u &\bnf& x \bnfor \lambda (x:A).t \bnfor t\ u \bnfor \Pi (x:A). B
    \bnfor \Type \\
    \Ga, \D &\bnf& \ctxempty \bnfor \Ga, x:A
  \end{array}
\]

\begin{mathpar}
  \infer
    {(x : A) \in \Ga}
    {\Ga \vdash x : A}
  %

  \infer
    {
      \Ga \vdash A : \Type \\
      \Ga, x : A \vdash B : \Type
    }
    {\Ga \vdash \Pi (x:A).\ B : \Type}
  %

  \infer
    {
      \Ga, x :A \vdash t : B \\
      \Ga \vdash \Pi (x:A).\ B : \Type
    }
    {\Ga \vdash \lambda (x:A).t : \Pi (x:A).\ B}
  %

  \infer
    {
      \Ga \vdash u : \Pi (x:A).\ B \\
      \Ga \vdash v : A
    }
    {\Ga \vdash u\ v : B[x \sto v]}
  %
\end{mathpar}
\marginnote[-3cm]{
  Here I changed a bit the typing rule for \(\lambda\)-abstraction to also ask
  for its type to be well-formed. This is necessary to ensure we put legitimate
  types in the context.
}

We usually also add a definition of well-formed context to ensure it is
comprised of types that make sense and that the dependencies are in order:
\marginnote[1cm]{
  As you can see, each type might depend on the previous variables.
}
\begin{mathpar}
  \infer
    { }
    {\vdash \ctxempty}
  %

  \infer
    {
      \vdash \Ga \\
      \Ga \vdash A : \Type
    }
    {\vdash \Ga, x:A}
  %
\end{mathpar}

\section{Dependent types in \Coq}

In this thesis I will often refer to the type theory of \Coq as well as give
some definitions in it. I will give here a brief introduction to it with
examples, but this does not aim at being a tutorial or a manual for \Coq.

In \Coq, \(\Pi\)-types are written
\begin{minted}{coq}
forall (x : A), B
\end{minted}
and \(\lambda\)-abstractions are written
\begin{minted}{coq}
fun (x : A) => t
\end{minted}
In both cases the domain (\mintinline{coq}{A}) can be left out if \Coq manages
to infer it from the context:
\marginnote[0.4cm]{
  \mintinline{coq}{nat} is the built-in type of natural numbers.
}
\begin{minted}{coq}
fun x => x + 0 : nat -> nat
\end{minted}

The polymorphic identity function of earlier is
\begin{minted}{coq}
fun A x => x : forall A, A -> A
\end{minted}
We can write it as a definition in the systems as follows:
\marginnote[0.4cm]{
  The squigly brackets indicate that the argument \mintinline{coq}{A} is
  implicit so that we can later write \mintinline{coq}{id 0} so that \Coq infers
  that \mintinline{coq}{A} is \mintinline{coq}{nat}.
}
\begin{minted}{coq}
Definition id {A : Type} (x : A) : A := x.
\end{minted}

Writing down functions is not the only way to define terms in \Coq however.
One of its strengths is the tactic mechanism that it is equipped with which
allows the user to write proofs in an interactive way.
Instead of writing the polymorphic identity function we could prove the
mathematical statement \(\forall A, A \to A\).
\begin{minted}{coq}
Fact id_as_proof :
  forall A, A -> A.
Proof.
  intro A.
  intro x.
  assumption.
Qed.
\end{minted}
The way this works is that we first state what we wish to prove
\begin{minted}{coq}
forall A, A -> A
\end{minted}
and how we want to refer to that fact afterwards
(\mintinline{coq}{id_as_proof}).
After the keyword \mintinline{coq}{Proof}, \Coq is in interactive mode,
telling the user what they have to prove to conclude the proof.
At the beginning this is still the full statement
\marginnote[0.4cm]{
  The horizontal bar separates the hypotheses (above) from the goal to prove
  (below).
}
\begin{minted}{coq}
-----------------
forall A, A -> A
\end{minted}
The user can then write tactics to progress with the proof. To prove a
quantified statement, as usual, you want to assume some element in particular
and prove the statement for that one. This is what the tactic
\mintinline{coq}{intro} does.
After writing
\begin{minted}{coq}
  intro A.
\end{minted}
the \emph{goal} becomes
\begin{minted}{coq}
A : Type
-----------------
A -> A
\end{minted}
We have now \emph{introduced} \mintinline{coq}{A} in our context and need to
prove \mintinline{coq}{A -> A}.
\begin{minted}{coq}
  intro x.
\end{minted}
will take some \mintinline{coq}{x : A}, bringing us to the new goal
\begin{minted}{coq}
A : Type
x : A
-----------------
A
\end{minted}
Proving \mintinline{coq}{A}, when we have \mintinline{coq}{A} as an hypothesis
should be pretty straightforward. The tatic \mintinline{coq}{assumption}
tells \Coq that the goal can be concluded using one of the assumptions in the
context (here \mintinline{coq}{x}).
This generates a term, and when we write \mintinline{coq}{Qed} it is checked
by \Coq to be correct.

As one should expect this produces the same term as before
\begin{minted}{coq}
id_as_proof = fun A x => x
            : forall A, A -> A
\end{minted}

There is of course much more to it and \nrefch{usual-defs} will offer some
usual definitions in type theory and in the context of \Coq.