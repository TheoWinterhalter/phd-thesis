% \setchapterpreamble[u]{\margintoc}
\chapter{Syntax and formalisation of type theory}
\labch{formalisation}

An interesting fact of type theory (and perhaps one its main selling points) is
that it is a suitable framework in which to reason about type theory.
That being said, representing type theory in itself isn't entirely
straightforward, and some care must be taken. There are actually several choices
to be made when representing type theory and they are not all equivalent or with
the same pros and cons.
I will detail some of them, spending more time on those I ended up choosing
and will try to motivate my choice.

In this chapter I will refer to work done in conjunction with Andrej Bauer and
Philipp Haselwarter called \ftt~\sidecite{formaltypetheory}.

\section{Representation of syntax}

I will first focus on the syntactical side of type theory.
The first important choice being how to represent variables.

\subsection{How to deal with variables}

When writing programs or expressions with binders on paper or on the computer
we will usually use \emph{names}, identifiers for variables like in
\(\lambda x. \lambda y. x\ y\), \(x\) refers to the variable bound by le
outermost \(\lambda\), while \(y\) referes to the variable bound by the
innermost.
The names aren't fundamental in what the term represents:
\(\lambda z. \lambda w. z\ w\) represents \emph{exactly} the same term.
We call this operation \(\alpha\)-renaming, here I \(\alpha\)-renamed \(x\)
to \(z\) and \(y\) to \(w\). This defines the notion of \(\alpha\)-equality
or \(\alpha\)-equivalence.
\[
  \lambda x. \lambda y. x\ y =_\alpha \lambda z. \lambda w. z\ w
\]
However variable names should only be thought of as an abstraction to represent
such terms and not a part of the syntax in itself.

Thinking in terms of variables name can lead to unpleasant examples where
\(\alpha\)-renaming might become a necessity.
For instance, \(\lambda x. \lambda x. x\) is perfectly valid but is easier to
read when renamed to \(\lambda y. \lambda x. x\). This process is called
\emph{shadowing}, when several variables bear the same name in scope, it is the
innermost that takes precedence. This principle is crucial for compositionality.

Even more problems arise when considering substitutions (after all, that is what
variables are for: to be substituted).
If you consider the term \(t \coloneqq x\ (\lambda x. x)\) we have two
occurrences of the name \(x\) but they do \emph{not} represent the same
variable, the first \(x\) is \emph{free} in the term, while the second is
\emph{bound} by the only \(\lambda\).
Now when substituting \(x\) for term \(u\) in \(t\), one has to be careful not
to replace the bound variable \(x\). The expected result is
\[
  t[x \sto u] = u\ (\lambda x. x)
\]
This used to be called \emph{capture-avoiding} substitutions, but I will call
them substitutions, because the operation yielding \(u\ (\lambda x. u)\)
is utterly rubbish and not deserving of a name.

Several solutions have been proposed to this ``problem'' like nominal
sets~\sidecite[-0.4cm]{pitts2001nominal},
\acrfull{HOAS}~\sidecite[0.3cm]{pfenning1988higher} and de Bruijn indices or
levels~\sidecite[0.6cm]{de1978lambda}.
In think de Bruijn indices are exactly what we want when dealing with
\(\lambda\)-terms as they carry the right amount of information.
The idea is to use natural numbers instead of names to indicate how many binders
to traverse before reaching the one introducing the variable.
\[
  \begin{array}{rcl}
    \lambda x.\ \lambda y.\ \lambda z.\ z
    &\to& \lambda\ \lambda\ \lambda\ \db{0} \\
    \lambda x.\ \lambda y.\ \lambda z.\ y
    &\to& \lambda\ \lambda\ \lambda\ \db{1} \\
    \lambda x.\ \lambda y.\ \lambda z.\ x
    &\to& \lambda\ \lambda\ \lambda\ \db{2}
  \end{array}
\]
In this setting the same variable can be represented in different ways:
\[
  \lambda x.\ x\ (\lambda y.\ x\ y)
\]
becomes
\[
  \lambda\ \db{0}\ (\lambda\ \db{1}\ \db{0})
\]
so that \(x\) is now written \(\db{0}\) and \(\db{1}\) depending on whether it
is referenced under the second \(\lambda\) or not.
The following diagram should make things more explicit.

\begin{center}
  \begin{tikzpicture}[remember picture]
    \node (term) {
      \(\subnode{la}{\(\lambda\)}\ \subnode{va}{\(\db{0}\)}\
      (\subnode{lb}{\(\lambda\)}\ \subnode{vb}{\(\db{1}\)}\
      \subnode{vc}{\(\db{0}\)})\)
    } ;
    \draw[barrow, bend right] (va.north) to (la.north) ;
    \draw[barrow, bend left] (vb.south) to (la.south) ;
    \draw[barrow, bend right] (vc.north) to (lb.north) ;
  \end{tikzpicture}
\end{center}

Using this representation, both \(\lambda x.x\) and \(\lambda y.y\) are written
\[
  \lambda\ \db{0}
\]
so that \(\alpha\)-equality is purely syntactic equality.
\(\alpha\)-renaming is not only a problem for pretty-printing.
This also solves the problem of substitutions potentially capturing free
variables: the term \(t \coloneqq x\ (\lambda x.\ x)\) of before is now
\(\db{n}\ (\lambda\ \db{0})\) where \(n\) is some number which should point to
somewhere in the context (same as the \(x\) it replaces).

Notice however that using de Bruijn indices, weakening---\ie putting a term into
an extended context---will now affect the term itself.
If you consider the following weakening, adding one variable \(z\) in the middle
of the context, doesn't affect the term using names.
\marginnote[1cm]{
  I use variables in the scope to make clear where the new variable is inserted
  in the nameless case.
}
\[
  x : A, y : B \vdash x\ y\ (\lambda u.\ x\ y\ u)
  \leadsto
  x : A, z : C, y : B \vdash x\ y\ (\lambda u.\ x\ y\ u)
\]
In the context of de Bruijn indices this becomes
\[
  A, B \vdash
  \highlight{\db{1}}\ \db{0}\ (\lambda\ \highlight{\db{2}}\ \db{1}\ \db{0})
  \leadsto
  A, C, B \vdash
  \highlight{\db{2}}\ \db{0}\ (\lambda\ \highlight{\db{3}}\ \db{1}\ \db{0})
\]


\subsection{Substitutions}

Another choice that is close to the representation of variable is that of
substitutions. There are several ways to represent a substitution in itself,
but I think the main question is whether to make them \emph{explicit} or not,
\ie part of the syntax or not.

With explicit substitutions \(t[\sigma]\) is a term in itself and things like
evaluation of substitutions come as reduction rules:
\[
  x[\sigma] \red \sigma(x)
\]
The question of how you represent substitutions is more curcial in this case,
and there are several ways to do so, the first being introduced in
\sidecite{abadi1991explicit}.

In \ftt where we formalised syntax of type theory in \Coq using explicit
substitutions we settled on the following constructions (I will give them
using typing rules to make their behaviour explicit):
\begin{mathpar}
  \infer
    {\Ga \vdash u : A}
    {\sbzero{A}{u} : \Ga \to \Ga,A}
  %

  \infer
    {\Ga \vdash A}
    {\sbweak{A} : \Ga \to \Ga, A}
  %

  \infer
    {
      \sigma : \Ga \to \D \\
      \D \vdash A
    }
    {\sbshift{A}{\sigma} : \Ga, A[\sigma] \to \D, A}
  %

  \infer
    {\vdash \Ga}
    {\sbid : \Ga \to \Ga}
  %

  \infer
    {
      \sigma : \Ga \to \D \\
      \theta : \D \to \Xi
    }
    {\theta \circ \sigma : \Ga \to \Xi}
  %

  \infer
    {\vdash \Ga}
    {\sbterminal : \Ga \to \ctxempty}
  %
\end{mathpar}

With computation rules such as
\[
  \begin{array}{rcl}
    \db{0}[\sbzero{A}{u}] &\red& u \\
    (\db{n+1})[\sbzero{A}{u}] &\red& \db{n} \\
    \db{n}[\sbweak{A}] &\red& \db{n+1} \\
    \db{0}[\sbshift{A}{\sigma}] &\red& \db{0} \\
    (\db{n+1})[\sbshift{A}{\sigma}] &\red& \db{n}[\sigma][\sbweak{A[\sigma]}] \\
    &\dots&
  \end{array}
\]

However, I find the other option of having substitutions as a meta-operation,
outside of the syntax, more natural. It also helps in keeping the syntax and
rules to a minimum while turning the substitutions notions above into
definitions and properties.
For instance weakening becomes a lemma and not something postulated with the
constructor \(\sbweak{}\).
I will not make a strong case for either choice however as they both have their
own interest.
Note that in \MetaCoq we go with meta-level substitutions.

\subsection{Annotations}

I already touched on this in \nrefch{models}, especially in conclusion of the
cardinal model of type theory, but I will once again talk about annotations
in a broader setting.

The fist question regards annotations of \(\lambda\)-abstractions with the
domain of the function, that is
\[
  \begin{array}{rcl}
    \lambda (x : A).\ t &\vs& \lambda x.\ t
  \end{array}
\]
This opposes the so-called Churh-style (annotation of the domain) to
Curry-style (no annotation whatsoever).
There is eve a third option of including the codomain \(\lambda (x:A).B.\ t\)
that seems necessary for \acrshort{ETT} according to the cardinal model.
\reminder[-0.7cm]{Uniqueness of type}{
  A type theory has uniqueness of type when
  \(\Ga \vdash t : A\) and \(\Ga \vdash t : B\) imply
  \(A \equiv B\).
}
Forgetting the latter there is already a pivot between Church- and Curry-style
in that plays a determinant role in uniqueness of type.
Indeed one cannot hope to have uniqueness of type given that
\(\lambda x.\ x\) has type \(A \to A\) for any \(A\).
The domain annotation is the minimal information required to get uniqueness of
type for \(\lambda\)-abstractions. This miminal information is equivalent to the
minimal information required for infering the type.
This information is minimal in the sense that any more annotations can be
recovered from a theory without them.

\subsection{Universes and types}

Another point of choice is whether to separate types and terms, putting them in
different syntactic classes. One of the great advantages of dependent type
theory over simple type theory is that types and terms can be expressed using
the same language. Keeping them separate might also make sense.

In case we want to keep them distinct, we have to duplicate concepts a bit:
substitution, weakening, and even typing: we have judgments \(\Ga \vdash A\)
for types and \(\Ga \vdash t : A\) for terms.
One of the advantages of this, is that no universes are required to say that
\eg \(\Pi\)-types are in the theory:
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga, A \vdash B
    }
    {\Ga \vdash \Pi\ A\ B}
  %
\end{mathpar}

This difference become clearer when considering the two main notion of
universes: namely Tarski and Russel universes.

\paradot{Tarski universes}

I already gave a brief presentation of Tarski universes when looking at
categorical models of type theory in \nrefch{models}.
A Tarski universe is a type of \emph{codes} of types, \ie they are terms
representing types. They can de decoded to types using the \(\CEl\) (element)
type constructor.
\begin{mathpar}
  \infer
    {\vdash \Ga}
    {\Ga \vdash \CU}
  %

  \infer
    {\Ga \vdash a : \CU}
    {\Ga \vdash \CEl\ a}
  %
\end{mathpar}

We then need a code for each type we want in this universe (otherwise we only
have variables). For instance here are the codes for \(\Pi\)-types.
\begin{mathpar}
  \infer
    {
      \Ga \vdash a : \CU \\
      \Ga \vdash b : \CEl\ a \to \CU
    }
    {\Ga \vdash \pi(a,b) : \CU}
  %
\end{mathpar}
To relate them to actual \(\Pi\)-types, we simply add computation rules to
\(\CEl\).
\[
  \CEl(\pi(a,b)) \red \Pi (x : \CEl\ a).\ \CEl\ (b\ x)
\]
Arguably we don't even need that, and to avoid duplication we could simply keep
the \(\CEl\)s everywhere
\marginnote[1cm]{
  The \(\lambda (\highlight{x:a}).\ t\) is not a typo. I enfore here \(\lambda\)
  to use codes in their syntax since one should not be able to abstract over
  a type that isn't some \(\CEl\ a\).
}
\begin{mathpar}
  \infer
    {
      \Ga \vdash a : \CU \\
      \Ga, x : \CEl\ a \vdash b : \CU \\
      \Ga, x : \CEl\ a \vdash t : \CEl\ (b\ x)
    }
    {\Ga \vdash \lambda (x:a).\ t : \CEl\ (\pi(a,b))}
  %

  \infer
    {
      \Ga \vdash a : \CU \\
      \Ga, x : \CEl\ a \vdash b : \CU \\
      \Ga \vdash f : \CEl\ (\pi(a,b)) \\
      \Ga \vdash u : \CEl\ a
    }
    {\Ga \vdash f\ u : \CEl\ (b\ u)}
  %
\end{mathpar}
I still prefer having a notion of \(\Pi\)-types that is independent of universes
and codes so that their behaviour is defined once and for all for every
universe.

\paradot{Russel universes}

The other option, the one used in \Coq, \Agda and most type-theory-based proof
assistants, is to use Russel universes. In this setting types are just terms
that inhabit a universe:
\[
  \Ga \vdash A : \Type
\]
As such we don't need something like \(\CEl\) to bridge between the two worlds.
In a sense, this is a special case of Tarki universes where codes are types
and \(\CEl\) is the identity function.

With Russel universes \(\Pi\)-types are typed as follows:
\begin{mathpar}
  \infer
    {
      \Ga \vdash A : \Type \\
      \Ga, A \vdash B : \Type
    }
    {\Ga \vdash \Pi\ A\ B : \Type}
  %
\end{mathpar}

When formalising universes there is a trade-off between the concise Russel
universes and the compartmentalised Tarski universes. On the interface with a
user however, I think universes are best when they are the least invasive, which
works better in a Russel setting. This doesn't prevent the system from having
Tarski universes under the hood.

\subsection{Formalisation of syntax}

Now that I have laid out a few design choices, I will talk a bit about how to
formalise the syntax of a type theory.
As I already mentioned I worked with two such representations, the one in
\MetaCoq and the one in \ftt, both in \Coq.

In \MetaCoq we use an inductive type to represent terms of which I give an
excerpt below:
\begin{minted}{coq}
Inductive term :=
| tRel (n : nat)
| tSort (u : Universe.t)
| tProd (na : name) (A B : term)
| tLambda (na : name) (A t : term)
| tLetIn (na : name) (b B t : term)
| tApp (u v : term)
| tConst (k : kername) (ui : Instance.t)
| tInd (ind : inductive) (ui : Instance.t)
| tConstruct (ind : inductive) (n : nat) (ui : Instance.t)
| tCase
    (indn : inductive * nat)
    (p c : term)
    (brs : list (nat * term))
| tProj (p : projection) (c : term)
| tFix (mfix : mfixpoint term) (idx : nat).
\end{minted}

\begin{itemize}
  \item \mintinline{coq}{tRel n} represents the \(n\)-th de Bruijn index
  \(\db{n}\);
  \item \mintinline{coq}{tSort u} is a universe, as described in the
  \mintinline{coq}{Universe} module;
  \item \mintinline{coq}{tProd na A B} represents a \(\Pi\)-type, herein
  \mintinline{coq}{na} is a \mintinline{coq}{name}: even though we use de Bruijn
  indices, we still have naming annotations for pretty-printing that are
  irrelevant for typing;
  \item \mintinline{coq}{tLambda na A t} represents a \(\lambda\)-abstraction;
  \item \mintinline{coq}{tLetIn na b B t} is a let-binding;
  \item \mintinline{coq}{tApp u v} is application of \mintinline{coq}{u} to
  \mintinline{coq}{v};
  \item the other constructors deal with constants, inductive types and their
  constructors, pattern-matching and fixed-points.
\end{itemize}

In \MetaCoq we try to stick as close as possible to the \Coq implementation,
whereas in \ftt we used a different approach, trying to be modular on the
syntax. Instead of using an inductive type, we use a record with fields for the
types of types, terms, etc. as well as the different syntactic constructs.
Here is also an excerpt of it.
\begin{minted}{coq}
Record Syntax := {
  context      : Type ;
  type         : Type ;
  term         : Type ;
  substitution : Type ;

  ctxempty  : context ;
  ctxextend : context -> type -> context ;

  Prod  : type -> type -> type ;
  Subst : type -> substitution -> type ;
  Uni   : level -> type ;
  El    : level -> term -> type ;

  var     : nat -> term ;
  lam     : type -> type -> term -> term ;
  app     : term -> type -> type -> term -> term ;
  subst   : term -> substitution -> term ;
  uniProd : level -> level -> term -> term -> term ;

  sbzero     : type -> term -> substitution ;
  sbweak     : type -> substitution ;
  sbshift    : type -> substitution -> substitution ;
  sbid       : substitution ;
  sbcomp     : substitution -> substitution -> substitution ;
  sbterminal : substitution
}.
\end{minted}
We also use de Bruijn indices, but most other choices I presented above aren't
made. It may seem like we use Tarski universes, separate terms and types, use
explicit substitutions and fully-annotated terms.
However, these aren't enforced because these aren't \emph{constructors}.
Nothing prevents us from providing an instance where \mintinline{coq}{term}
and \mintinline{coq}{type} are the same and \mintinline{coq}{El} is the identity
(hence Russel universes), functions that ignore the annotations for
\mintinline{coq}{app} and \mintinline{coq}{lam}, or meta-level functions for
the substitutions.
For instance, here is a version with explicit substitutions, but the rest as I
mentioned:
\begin{minted}{coq}
Inductive context : Type :=
| ctxempty : context
| ctxextend : context -> term -> context

with term : Type :=
(* Types *)
| Prod : term -> term -> term
| Uni : syntax.level -> term
(* Terms *)
| var : nat -> term
| lam : term -> term -> term
| app : term -> term -> term
| subst : term -> substitution -> term

with substitution : Type :=
| sbzero : term -> term -> substitution
| sbweak : term -> substitution
| sbshift : term -> substitution -> substitution
| sbid : substitution
| sbcomp : substitution -> substitution -> substitution
| sbterminal : substitution
.

Definition S : Syntax := {|
  context      := context ;
  type         := term ;
  term         := term ;
  substitution := substitution ;

  ctxempty  := ctxempty ;
  ctxextend := ctxextend ;

  Prod   := Prod ;
  Subst  := subst ;
  Uni    := Uni ;
  El i T := T ;

  var n           := var n ;
  lam A B t       := lam A t ;
  app u A B v     := app u v ;
  subst u sbs     := subst u sbs ;
  uniProd i j A B := Prod A B ;

  sbzero     := sbzero ;
  sbweak     := sbweak ;
  sbshift    := sbshift ;
  sbid       := sbid ;
  sbcomp     := sbcomp ;
  sbterminal := sbterminal
|}.

\end{minted}

There is however an important consequence of such a presentation: the syntax is
no longer inductive, so there is a priori no injectivity of constructors and
we might well define all those types to be \mintinline{coq}{unit}, identifying
all those constructs.
This can make it hard to reason about the syntax, and a lot of properties simply
do not hold because you cannot distinguish two different constructs.
As such I am not sure this is the best way to go.
In the remainder of this thesis, I will focus more on approached like that of
\MetaCoq.

Another approach I haven't mentioned yet is \acrfull{HOAS}.
\todo{HOAS}

\section{Representation of typing}

Now that we have a notion of syntax in mind, we can move on to representing
typing derivations---as well as the notion of conversion.
Once again, we are faced with many choices.

\subsection{Paranoia of typing rules}
\todo{paranoia formal-type-theory (including typed or untyped equality?)}

\subsection{How intricate need the concepts be?}

\todo{Well-typed syntax that I did not study in depth but needs to be
mentioned → maybe expose my idea that it isn't exactly the same,
notion of computation in the meta (→ translations).}

\todo{And conversion?}