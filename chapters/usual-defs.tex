% \setchapterpreamble[u]{\margintoc}
\chapter{Usual definitions in type theory}
\labch{usual-defs}

Dependent type theory as presented in \nrefch{dependent-types} is rather barren.
It really shines when extended with some interesting principles and datatypes.
I will give an overview of these features---with the \Coq proof assistant in
mind---and focus mainly on those that are relevant to this thesis.

\section{Inductive types}
\labsec{inductive-types}

Inductive types are probably the most emblematic feature of dependent type
theory. They are an extension of the variant datatypes present in \ocaml like
the type of lists.
\marginnote[0.6cm]{
  A list, say of integers, is either empty (\mintinline{ocaml}{nil}) or some
  head \mintinline{ocaml}{h : int} and some tail
  \mintinline{ocaml}{t : int list}, written \mintinline{ocaml}{cons h t}.
}
\begin{minted}{ocaml}
type 'a list =
| nil
| cons of 'a * 'a list
\end{minted}
They come in different flavours which I will try to explain.

\subsection{Variants}

The simplest case of inductive types is that of variants. They consist in a list
of different options.

\paradot{Booleans}

\(\bool\) is the type inhabited by \(\ttrue\) and \(\ffalse\).
\begin{mathpar}
  \infer
    { }
    {\Ga \vdash \bool}
  %

  \infer
    { }
    {\Ga \vdash \ttrue : \bool}
  %

  \infer
    { }
    {\Ga \vdash \ffalse : \bool}
  %
\end{mathpar}

In \Coq you would write it as follows:
\begin{minted}{coq}
Inductive bool : Type :=
| true
| false.
\end{minted}
Of course, having those is not nearly enough without the usual
\(\mathsf{if}\) construct.
For instance \mintinline{coq}{if b then 0 else 1} will return
\mintinline{coq}{0} if \mintinline{coq}{b} is \mintinline{coq}{true}
and \mintinline{coq}{1} if it is \mintinline{coq}{false}.
This is already something that makes sense in the simple
case\sidenote{See \nrefch{simple-types}}, but with dependent types the case
analysis is also dependent on the scrutinee.
\begin{mathpar}
  \infer
    {
      \Ga \vdash b : \bool \\
      \Ga, x : \bool \vdash P \\
      \Ga \vdash u : P[x \sto \ttrue] \\
      \Ga \vdash v : P[x \sto \ffalse]
    }
    {\Ga \vdash \tif{b}{x.P}{u}{v}}
  %
\end{mathpar}
Before we break down the typing rule, let me show you the computational
behaviour of \(\mathsf{if}\).
\begin{mathpar}
  \begin{array}{lcl}
    \tif{\ttrue}{x.P}{u}{v} &\red& u \\
    \tif{\ffalse}{x.P}{u}{v} &\red& v
  \end{array}
\end{mathpar}
It is still the same as the well-known \(\mathsf{if}\), except that we are more
liberal in the types given to the two branches: they don't have to match as they
can now depend on the boolean. The \(x.P\) notation means that \(P\) lives in a
context extended by \(x\) (of type \(\bool\)).

The \(\mathsf{if}\) is actually just a notation for a more generic construction
called \emph{pattern-matching}. \(\tif{b}{x.P}{u}{v}\) is in fact the term
\[
  \pmatch{b}{x.P}{
    \branch{\ttrue}{u} \\
    \branch{\ffalse}{v}
  }
\]
It describes the case analysis by saying which constructor is sent to which
term. If the scrutinee---here \(b\)---\emph{matches} one of the branches on
left-hand side of \(\mto\), the whole expression will reduce to the
corresponding right-hand side.

\paradot{Unit}

The \(\unit\) type is similar to \(\bool\) but has only one constructor written
\(\tunit\).
\begin{mathpar}
  \infer
    { }
    {\Ga \vdash \unit}
  %

  \infer
    { }
    {\Ga \vdash \tunit : \unit}
  %
\end{mathpar}

In \Coq it is defined as:
\begin{minted}{coq}
Inductive unit : Type :=
| tt.
\end{minted}
And the notation mechanism can help use write \mintinline{coq}{tt}
as \mintinline{coq}{()}.
Once again, pattern-matching allows us to inspect a proof of \(\unit\):
\begin{mathpar}
  \infer
    {
      \Ga \vdash u : \unit \\
      \Ga, x:\unit \vdash P \\
      \Ga \vdash v : P[x \sto \tunit]
    }
    {
      \Ga \vdash
      \pmatch{u}{x.P}{
        \branch{\tunit}{v}
      }
      : P[x \sto u]
    }
  %
\end{mathpar}
This might seem a bit useless, but essentially it means that to prove anything
involving a dependency on \(\unit\), like \(P[x \sto u]\), it suffices to prove
it assuming it is \(\tunit\): \(P[x \sto \tunit]\).
When the term \(u\) was already \(\tunit\), the \(\mathsf{match}\) can go away:
\[
  \pmatch{\tunit}{x.P}{\branch{\tunit}{v}} \red v
\]

Sometimes this type is called \(\top\) as in the logical triviality.

\paradot{Empty type}

The empty (or false) type, \(\bot\) is the dual of the unit type. This time it
has no constructors \emph{at all}.
\begin{mathpar}
  \infer
    { }
    {\Ga \vdash \bot}
  %
\end{mathpar}

In \Coq, it is written in a rather queer manner.
\begin{minted}{coq}
Inductive False :=.
\end{minted}

It represents the data that should never exist, so any term of type \(\bot\)
is a \emph{contradiction} with the hyptheses at hand.
Even though it does not have constructors, pattern-matching still makes sense on
such terms.
\marginnote[1.6cm]{
  The pattern-matching does not have any branches, hence the empty space.
}
\begin{mathpar}
  \infer
    {
      \Ga \vdash t : \bot \\
      \Ga, x:\bot \vdash P
    }
    {\Ga \vdash \pmatch{t}{x.P}{} : P[x \sto t]}
  %
\end{mathpar}
This is the essence of the \emph{principle of explosion}:
\emph{ex falso quodlibet}, from falsehood, anything follows.
Here we are able to conjure some inhabitant of \(P[x \sto t]\) from thin air.
The \(P\) is typically not dependent on the proof of \(\bot\), meaning that from
an inhabitant of \(\bot\) we can get an inhabitant of \emph{any} type.

\subsection{Recusrive types}

Inductive types are morally types of trees. For now I only prensented types
consisting only of leaves. To allow for nodes with subtrees, constructors can
take subtrees (or subterms) as arguments.
The best and simplest example of those is that of natural numbers.

\paradot{Natural numbers}

The way we represent \emph{unary} natural numbers in type theory is by saying
a natural number is either \(0\) or the successor of another natural number
\(n\), \ie \(n + 1\). We usually write the successor operation \(\natsucc\).
So natural numbers are \(0\), \(\natsucc\ 0\), \(\natsucc\ (\natsucc\ 0)\), etc.
\marginnote[2.7cm]{
  Notice how \(u_\natsucc\) is allowed to mention \(m\). The variable is bound
  by the pattern \(\natsucc\ m\) on the left-hand side.
}
\begin{mathpar}
  \infer
    { }
    {\Ga \vdash \nat}
  %

  \infer
    { }
    {\Ga \vdash \zero : \nat}
  %

  \infer
    {\Ga \vdash n : \nat}
    {\Ga \vdash \natsucc\ n : \nat}
  %

  \infer
    {
      \Ga \vdash n : \nat \\
      \Ga, x:\nat \vdash P \\
      \Ga \vdash u_\zero : P[x \sto \zero] \\
      \Ga, m:\nat \vdash u_\natsucc : P[x \sto \natsucc\ m]
    }
    {
      \Ga \vdash
      \pmatch{n}{x.P}{
        \branch{\zero}{u_\zero} \\
        \branch{\natsucc\ m}{u_\natsucc}
      }
      : P[x \sto n]
    }
  %
\end{mathpar}
Together with the computation rules
\[
  \begin{array}{lcl}
    \pmatch{\zero}{x.P}{
      \branch{\zero}{u_\zero} \\
      \branch{\natsucc\ m}{u_\natsucc}
    }
    &\red&
    u_\zero \\
    \pmatch{\natsucc\ n}{x.P}{
      \branch{\zero}{u_\zero} \\
      \branch{\natsucc\ m}{u_\natsucc}
    }
    &\red&
    u_\natsucc[m \sto n]
  \end{array}
\]

As with the previous examples, this allows us to do case analysis on natural
numbers but this is no longer sufficient to effectively reason on them.
The bare minimum we would require is to do induction on natural numbers.

There are two main ways of achieving this.
\begin{itemize}
  \item \emph{Eliminators.} This method consists in assuming the induction
  principle of \(\nat\) directly.
  \[
    \natrec :
      \Pi\ P.\
        P\ \zero \to
        (\Pi n.\ P\ n \to P\ (\natsucc\ n)) \to
        \Pi n. P\ n
  \]
  There are ways to generate them automatically~\sidecite{kovacs2020signatures}
  and \Coq does it to some extent. The troublesome part is getting the
  right computation rules and dealing with nested inductive types.
  In this case, the computation rules are
  \[
    \begin{array}{lcl}
      \natrec\ P\ p_\zero\ p_\natsucc\ \zero &\red& p_\zero \\
      \natrec\ P\ p_\zero\ p_\natsucc\ (\natsucc\ n) &\red&
      p_\natsucc\ n\ (\natrec\ P\ p_\zero\ p_\natsucc\ n) \\
    \end{array}
  \]

  \item \emph{Fixed-points.} The method used in \Coq comes from a combination of
  pattern-matching and a fixed-point operator.
  \marginnote[0.7cm]{
    The notation \(\Pi \D. T\) is to quantify over a whole context.
    If \(\D\) is \(x : A, y : B\), \(\Pi \D. T\) is \(\Pi (x:A)\ (y:B).\ T\).
    When \(\D\) is empty, this is just \(T\).
  }
  \[
    \infer
      {
        \Ga \vdash \Pi \Delta. T \\
        \Ga, f : \Pi \Delta. T, \D \vdash t : T \\
        \highlight{f \vdash_n t \text{ termination checks}}
      }
      {\Ga \vdash \fixp_n (f : \Pi \Delta. T).\ t : \Pi \Delta. T}
    %
  \]
  The termination checking condition roughly verifies that the \(n\)-th argument
  in \(\D\) is only fed to \(f\) (\ie recursive calls) in a decreasing manner.
  This so-called guard condition is a complicated matter and out of scope of
  this thesis and probably better studied in
  \sidecite{gimenez1998structural}. In general this can be thought as only
  subterms of the argument are passed on to \(f\).
  The computational behaviour of the fixed-point operator is via unfolding of
  its definition.
  \[
    \fixp_n (f : \Pi \D.T).\ t \red
    \lambda \D.\ t[f \sto \fixp_n (f : \Pi \D.T).\ t]
  \]
  Of course, doing this would defeat the purpose of the termination checker:
  ensuring that the obtained definition terminates. As you can see you can
  unfold the fixed-point indefinitely.
  The way we prevent that is by using a syntactical guard on the reduction rule.
  It is instead the following.
  \marginnote[0.6cm]{
    \(\mathbf{C}\) stands for a constuctor like \(\zero\) or \(\natsucc\).
  }
  \[
    \begin{array}{lc}
      (\fixp_n (f : \Pi \D.T).\ t)\
      u_1\ \dots\ u_{n-1}\ (\mathbf{C}\ v_1\ \dots\ v_m)
      &\red \\
      (\lambda \D.\ t[f \sto \fixp_n (f : \Pi \D.T).\ t])\
      u_1\ \dots\ u_{n-1}\ (\mathbf{C}\ v_1\ \dots\ v_m)
    \end{array}
  \]
  We can then write down the induction principle \(\natrec\) with \(\fixp\)
  and \(\mathsf{match}\).
  \marginnote[2cm]{
    Notice how \(m\) is a subterm of \(\natsucc\ m\) in the recursive call to
    \(f\). It is indeed its fourth argument.
  }
  \[
    \begin{array}{l}
      \fixp_4\ (f : \Pi\ P\ p_\zero\ p_\natsucc\ n.\ P\ n). \\
      \pmatch{n}{x.\ P\ x}{
        \branch{\zero}{p_\zero} \\
        \branch
          {\natsucc\ m}
          {p_\natsucc\ m\ (f\ P\ p_\zero\ p_\natsucc\ \highlight{m})}
      }
    \end{array}
  \]
  It will have the same reduction rules as the eliminator shown above.
\end{itemize}

I won't go into that much detail for other inductive types as they will all
follow more or less the same schema.

\subsection{Parameterised inductive types}

Parameterised inductive types, as the name suggests, can take parameters.
In \ocaml, parameters are necessarily types, and it is often the case in \Coq
though everything goes.

\paradot{Lists}

I already presented lists in \ocaml, and their \Coq counterpart isn't much
different.
\begin{mathpar}
  \infer
    {\Ga \vdash A}
    {\Ga \vdash \tlist\ A}
  %

  \infer
    {\Ga \vdash A}
    {\Ga \vdash \nil : \tlist\ A}
  %

  \infer
    {
      \Ga \vdash A \\
      \Ga \vdash h : A \\
      \Ga \vdash t : \tlist\ A
    }
    {\Ga \vdash h :: t : \tlist\ A}
  %

  \infer
    {
      \Ga \vdash l : \tlist\ A \\
      \Ga, x : \tlist\ A \vdash P \\
      \Ga \vdash u_\nil : P[x \sto \nil] \\
      \Ga, h : A, t : \tlist\ A \vdash u_{::} : P[x \sto h :: t]
    }
    {
      \Ga \vdash
      \pmatch{l}{x.P}{
        \branch{\nil}{u_\nil} \\
        \branch{h :: t}{u_{::}}
      }
      : P[x \sto l]
    }
  %
\end{mathpar}
The computation rules are the ones you should expect by now.
Similarly to natural numbers, that can be combined with the fixed-point operator
to perform induction on lists, the type of which is
\[
  \Pi\ A\ (P : \tlist\ A \to \Type).\
  P\ \nil \to
  (\Pi\ h\ t.\ P\ t \to P\ (h :: t)) \to
  \Pi\ l.\ P\ l
\]

\paradot{Options}

\(\option\ A\) represents a potential data of type \(A\) but it could also not
be present. It is optional.
\begin{mathpar}
  \infer
    {\Ga \vdash A}
    {\Ga \vdash \option\ A}
  %

  \infer
    {\Ga \vdash a : A}
    {\Ga \vdash \some\ a : \option\ A}
  %

  \infer
    {\Ga \vdash A}
    {\Ga \vdash \none : \option\ A}
  %

  \infer
    {
      \Ga \vdash o : \option\ A \\
      \Ga, x : \option\ A \vdash P \\
      \Ga, a : A \vdash u_\some : P[x \sto \some\ a] \\
      \Ga \vdash u_\none : P[x \sto \none]
    }
    {
      \Ga \vdash
      \pmatch{o}{x.P}{
        \branch{\some\ a}{u_\some} \\
        \branch{\none}{u_\none}
      }
      : P[x \sto o]
    }
  %
\end{mathpar}
It is an easy way of representing functions that are not defined on their whole
domain (they return \(\none\) when they are not).

\paradot{Sum types}

Simple sums \(A + B\) consist in a disjunction of cases. A proof of \(A + B\)
is either a proof of \(A\) or a proof of \(B\).
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga \vdash B
    }
    {\Ga \vdash A + B}
  %

  \infer
    {
      \Ga \vdash a : A \\
      \Ga \vdash B
    }
    {\Ga \vdash \inl\ a : A + B}
  %

  \infer
    {
      \Ga \vdash b : B \\
      \Ga \vdash A
    }
    {\Ga \vdash \inr\ b : A + B}
  %

  \infer
    {
      \Ga \vdash p : A + B \\
      \Ga, x : A + B \vdash P \\
      \Ga, a : A \vdash u : P[x \sto \inl\ a] \\
      \Ga, b : B \vdash v : P[x \sto \inr\ b]
    }
    {
      \Ga \vdash
      \pmatch{p}{x.P}{
        \branch{\inl\ a}{u} \\
        \branch{\inr\ b}{v}
      }
      : P[x \sto p]
    }
  %
\end{mathpar}

\paradot{Simple products}

Simple products \(A \times B\) are types of pairs of elements, one in \(A\)
and one in \(B\). None too surprising.
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga \vdash B
    }
    {\Ga \vdash A \times B}
  %

  \infer
    {
      \Ga \vdash a : A \\
      \Ga \vdash b : B
    }
    {\Ga \vdash (a,b) : A \times B}
  %

  \infer
    {
      \Ga \vdash p : A \times B \\
      \Ga, x : A \times B \vdash P \\
      \Ga, a : A, b : B \vdash t : P[x \sto (a,b)]
    }
    {
      \Ga \vdash
      \pmatch{p}{x.P}{
        \branch{(a,b)}{t}
      }
      : P[x \sto p]
    }
  %
\end{mathpar}

This presentation of pairs is called \emph{positive} as it uses a constructor.
In the section on records I will show the \emph{negative} version.

\paradot{\(\Sigma\)-types}

\marginnote[0.2cm]{
  In the simple case we have sums \(A + B\), products \(A \times B\)
  and exponentials \(B^A\) or \(A \to B\). In the dependent case however, it is
  all shifted: we have sums \(\Sigma A.B\) and products \(\Pi A.B\).
}
Dependent sums or \(\Sigma\)-types are a generalisation of simple products to
dependent types. They are the way to represent existential quantifier
(except in a---usually---constructive way): \(\Sigma (x:A).P\ x\) is proven by
giving a term \(t : A\) and a proof of \(P\ t\).
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga, x : A \vdash B
    }
    {\Ga \vdash \Sigma (x:A). B}
  %

  \infer
    {
      \Ga, x:A \vdash B \\
      \Ga \vdash a : A \\
      \Ga \vdash b : B[x \sto a]
    }
    {\Ga \vdash \dpair{a,b} : \Sigma (x:A).B}
  %

  \infer
    {
      \Ga \vdash p : \Sigma (x:A).B \\
      \Ga, x : \Sigma (x:A).B \vdash P \\
      \Ga, a : A, b : B[x \sto a] \vdash t : P[x \sto \dpair{a,b}]
    }
    {
      \Ga \vdash
      \pmatch{p}{x.P}{
        \branch{\dpair{a,b}}{t}
      }
      : P[x \sto p]
    }
  %
\end{mathpar}
Once more, this is the \emph{positive} presentation of \(\Sigma\)-types.
With this presentation it is also possible to restrict \(P\) in case we don't
want to make it possible to extract the witness (the \(a\) in \(\dpair{a,b}\)).

\marginnote[0.2cm]{
  The \(\_\) is there to note that \(B\) does not depend on the variable in
  \(A\).
}
It is also worth noting that simple products are a particular case of
\(\Sigma\)-type: \(A \times B\) can be defined as \(\Sigma (\_:A).B\).

\subsection{Indexed inductive types}

\marginnote[1cm]{
  In all the examples I showed, the parameters are \emph{uniform}, \ie they are
  the same everywhere, but there can be non uniform occurrences of them where
  the recursive argument is at a different parameter.
}
Inductive types can have parameters, but they can also have \emph{indices}.
They are similar to parameters in that they are arguments to the inductive type
but while parameters are always the same in the \emph{conclusion} of the type of
a constructor, indices can vary.
I will show the two most talked about cases of indexed inductive types: vectors
and equality.

\paradot{Vectors}

Vectors are length-indexed lists: \(\tvec_A\ n\) is type of lists of length
\(n\) whose elements inhabit \(A\). In this case, \(A\) is a parameter and
\(n\) is an index.
\marginnote[1cm]{
  I highlight the index for the constructors to show how it differs.
  \(\vnil\) is the only list of length \(0\) and a \(\vcons\) always adds one
  element to a vector.
}
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga \vdash n : \nat
    }
    {\Ga \vdash \tvec_A\ n}
  %

  \infer
    {\Ga \vdash A}
    {\Ga \vdash \vnil : \tvec_A\ \highlight{\zero}}
  %

  \infer
    {
      \Ga \vdash a : A \\
      \Ga \vdash n : \nat \\
      \Ga \vdash v : \tvec_A\ n
    }
    {\Ga \vdash \vcons\ a\ n\ v : \tvec_A\ \highlight{\natsucc\ n}}
  %

  \infer
    {
      \Ga \vdash v : \tvec_A\ n \\
      \Ga, p : \nat, x : \tvec_A\ p \vdash P \\
      \Ga \vdash u_\vnil : P[p \sto 0, x \sto \vnil] \\
      \Ga, a : A, m : \nat, w : \tvec_A\ m \vdash
      u_\vcons : P[p \sto \natsucc\ m, x \sto \vcons\ a\ m\ w]
    }
    {
      \Ga \vdash
      \pmatch{v}{p.x.P}{
        \branch{\vnil}{u_\vnil} \\
        \branch{\vcons\ a\ m\ w}{u_\vcons}
      }
      : P[p \sto n, x \sto v]
    }
  %
\end{mathpar}
The pattern-matching this time binds \emph{two} variables: the variable
representing the matched term as usual, but also the index! This is because it
varies depending on the branch.

Vectors are pretty useful because since you account for the length, you can
write safer and more precise functions. For instance, the tail function on lists
would land in an option type (in the case the list is \(\nil\)), but here we
can easily say it should only take some \(\tvec_A\ (\natsucc\ n)\) as argument,
ruling out the empty vector completely.
\marginnote[1.4cm]{
  The return type is also more precise: the tail of a list of length
  \(\natsucc\ n\) is of length \(n\).
}
\[
  \begin{array}{l}
    \lambda\ A\ (n : \nat)\ (v : \tvec_A\ (\natsucc\ n)). \\
    \pmatch{v}{p.x. \tvec_A\ n}{
      \branch{\vcons\ a\ m\ w}{w}
    }
  \end{array}
\]
Notice how I didn't even provide a branch for \(\vnil\) because it will always
by ill-typed. This is unfortunately impossible in vanilla \Coq but is supported
in \Agda natively and can be achived in \Coq with \Program of the \Equations
plugin~\sidecite{DBLP:conf/itp/Sozeau10,sozeau2019equations}.
With the typing rules I gave it is still possible to do it, it's just that we
have to conclude using the elimination of \(\bot\) in the \(\vnil\) branch.

\paradot{Equality}
\todo{TODO}

\subsection{Other inductive types}
\todo{Mutual}
\todo{Inductive Inductive/Recusrive? Probably irrelevant here}

\section{Coinductive types and records}

\section{Equality}
\labsec{equality-def}

\todo{This is not a debate about how to define it, we will show the Coq one
and refer to the next chapter to the discussion about its definition.}
\todo{UIP, funext, transport, heterogenous equality}

\acrfull{JMeq} introduced by
\sidecite{mcbride2000dependently} has axioms
instead better
\[ \Heq{T}{t}{U}{u} := \Sum{p:\Eq{}{T}{U}} \Eq{}{\transpo{p}\ t}{u}. \]