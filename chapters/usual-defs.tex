% \setchapterpreamble[u]{\margintoc}
\chapter{Usual definitions in type theory}
\labch{usual-defs}

Dependent type theory as presented in \nrefch{dependent-types} is rather barren.
It really shines when extended with some interesting principles and datatypes.
I will give an overview of these features---with the \Coq proof assistant in
mind---and focus mainly on those that are relevant to this thesis.

\section{Inductive types}
\labsec{inductive-types}

Inductive types are probably the most emblematic feature of dependent type
theory. They are an extension of the variant datatypes present in \ocaml like
the type of lists.
\marginnote[0.6cm]{
  A list, say of integers, is either empty (\mintinline{ocaml}{nil}) or some
  head \mintinline{ocaml}{h : int} and some tail
  \mintinline{ocaml}{t : int list}, written \mintinline{ocaml}{cons h t}.
}
\begin{minted}{ocaml}
type 'a list =
| nil
| cons of 'a * 'a list
\end{minted}
They come in different flavours which I will try to explain.

\subsection{Variants}

The simplest case of inductive types is that of variants. They consist in a list
of different options.

\paradot{Booleans}

\(\bool\) is the type inhabited by \(\ttrue\) and \(\ffalse\).
\begin{mathpar}
  \infer
    { }
    {\Ga \vdash \bool}
  %

  \infer
    { }
    {\Ga \vdash \ttrue : \bool}
  %

  \infer
    { }
    {\Ga \vdash \ffalse : \bool}
  %
\end{mathpar}

In \Coq you would write it as follows:
\begin{minted}{coq}
Inductive bool : Type :=
| true
| false.
\end{minted}
Of course, having those is not nearly enough without the usual
\(\mathsf{if}\) construct.
For instance \mintinline{coq}{if b then 0 else 1} will return
\mintinline{coq}{0} if \mintinline{coq}{b} is \mintinline{coq}{true}
and \mintinline{coq}{1} if it is \mintinline{coq}{false}.
This is already something that makes sense in the simple
case\sidenote{See \nrefch{simple-types}}, but with dependent types the case
analysis is also dependent on the scrutinee.
\begin{mathpar}
  \infer
    {
      \Ga \vdash b : \bool \\
      \Ga, x : \bool \vdash P \\
      \Ga \vdash u : P[x \sto \ttrue] \\
      \Ga \vdash v : P[x \sto \ffalse]
    }
    {\Ga \vdash \tif{b}{x.P}{u}{v}}
  %
\end{mathpar}
Before we break down the typing rule, let me show you the computational
behaviour of \(\mathsf{if}\).
\begin{mathpar}
  \begin{array}{lcl}
    \tif{\ttrue}{x.P}{u}{v} &\red& u \\
    \tif{\ffalse}{x.P}{u}{v} &\red& v
  \end{array}
\end{mathpar}
It is still the same as the well-known \(\mathsf{if}\), except that we are more
liberal in the types given to the two branches: they don't have to match as they
can now depend on the boolean. The \(x.P\) notation means that \(P\) lives in a
context extended by \(x\) (of type \(\bool\)).

The \(\mathsf{if}\) is actually just a notation for a more generic construction
called \emph{pattern-matching}. \(\tif{b}{x.P}{u}{v}\) is in fact the term
\[
  \pmatch{b}{x.P}{
    \branch{\ttrue}{u} \\
    \branch{\ffalse}{v}
  }
\]
It describes the case analysis by saying which constructor is sent to which
term. If the scrutinee---here \(b\)---\emph{matches} one of the branches on
left-hand side of \(\mto\), the whole expression will reduce to the
corresponding right-hand side.

\paradot{Unit}

The \(\unit\) type is similar to \(\bool\) but has only one constructor written
\(\tunit\).
\begin{mathpar}
  \infer
    { }
    {\Ga \vdash \unit}
  %

  \infer
    { }
    {\Ga \vdash \tunit : \unit}
  %
\end{mathpar}

In \Coq it is defined as:
\begin{minted}{coq}
Inductive unit : Type :=
| tt.
\end{minted}
And the notation mechanism can help use write \mintinline{coq}{tt}
as \mintinline{coq}{()}.
Once again, pattern-matching allows us to inspect a proof of \(\unit\):
\begin{mathpar}
  \infer
    {
      \Ga \vdash u : \unit \\
      \Ga, x:\unit \vdash P \\
      \Ga \vdash v : P[x \sto \tunit]
    }
    {
      \Ga \vdash
      \pmatch{u}{x.P}{
        \branch{\tunit}{v}
      }
      : P[x \sto u]
    }
  %
\end{mathpar}
This might seem a bit useless, but essentially it means that to prove anything
involving a dependency on \(\unit\), like \(P[x \sto u]\), it suffices to prove
it assuming it is \(\tunit\): \(P[x \sto \tunit]\).
When the term \(u\) was already \(\tunit\), the \(\mathsf{match}\) can go away:
\[
  \pmatch{\tunit}{x.P}{\branch{\tunit}{v}} \red v
\]

Sometimes this type is called \(\top\) as in the logical triviality.

\paradot{Empty type}

The empty (or false) type, \(\bot\) is the dual of the unit type. This time it
has no constructors \emph{at all}.
\begin{mathpar}
  \infer
    { }
    {\Ga \vdash \bot}
  %
\end{mathpar}

In \Coq, it is written in a rather queer manner.
\begin{minted}{coq}
Inductive False :=.
\end{minted}

It represents the data that should never exist, so any term of type \(\bot\)
is a \emph{contradiction} with the hyptheses at hand.
Even though it does not have constructors, pattern-matching still makes sense on
such terms.
\marginnote[1.6cm]{
  The pattern-matching does not have any branches, hence the empty space.
}
\begin{mathpar}
  \infer
    {
      \Ga \vdash t : \bot \\
      \Ga, x:\bot \vdash P
    }
    {\Ga \vdash \pmatch{t}{x.P}{} : P[x \sto t]}
  %
\end{mathpar}
This is the essence of the \emph{principle of explosion}:
\emph{ex falso quodlibet}, from falsehood, anything follows.
Here we are able to conjure some inhabitant of \(P[x \sto t]\) from thin air.
The \(P\) is typically not dependent on the proof of \(\bot\), meaning that from
an inhabitant of \(\bot\) we can get an inhabitant of \emph{any} type.

\subsection{Recusrive types}

Inductive types are morally types of trees. For now I only prensented types
consisting only of leaves. To allow for nodes with subtrees, constructors can
take subtrees (or subterms) as arguments.
The best and simplest example of those is that of natural numbers.

\paradot{Natural numbers}

The way we represent \emph{unary} natural numbers in type theory is by saying
a natural number is either \(0\) or the successor of another natural number
\(n\), \ie \(n + 1\). We usually write the successor operation \(\natsucc\).
So natural numbers are \(0\), \(\natsucc\ 0\), \(\natsucc\ (\natsucc\ 0)\), etc.
\marginnote[2.7cm]{
  Notice how \(u_\natsucc\) is allowed to mention \(m\). The variable is bound
  by the pattern \(\natsucc\ m\) on the left-hand side.
}
\begin{mathpar}
  \infer
    { }
    {\Ga \vdash \nat}
  %

  \infer
    { }
    {\Ga \vdash \zero : \nat}
  %

  \infer
    {\Ga \vdash n : \nat}
    {\Ga \vdash \natsucc\ n : \nat}
  %

  \infer
    {
      \Ga \vdash n : \nat \\
      \Ga, x:\nat \vdash P \\
      \Ga \vdash u_\zero : P[x \sto \zero] \\
      \Ga, m:\nat \vdash u_\natsucc : P[x \sto \natsucc\ m]
    }
    {
      \Ga \vdash
      \pmatch{n}{x.P}{
        \branch{\zero}{u_\zero} \\
        \branch{\natsucc\ m}{u_\natsucc}
      }
      : P[x \sto n]
    }
  %
\end{mathpar}
Together with the computation rules
\[
  \begin{array}{lcl}
    \pmatch{\zero}{x.P}{
      \branch{\zero}{u_\zero} \\
      \branch{\natsucc\ m}{u_\natsucc}
    }
    &\red&
    u_\zero \\
    \pmatch{\natsucc\ n}{x.P}{
      \branch{\zero}{u_\zero} \\
      \branch{\natsucc\ m}{u_\natsucc}
    }
    &\red&
    u_\natsucc[m \sto n]
  \end{array}
\]

As with the previous examples, this allows us to do case analysis on natural
numbers but this is no longer sufficient to effectively reason on them.
The bare minimum we would require is to do induction on natural numbers.

There are two main ways of achieving this.
\begin{itemize}
  \item \emph{Eliminators.} This method consists in assuming the induction
  principle of \(\nat\) directly.
  \[
    \natrec :
      \Pi\ P.\
        P\ \zero \to
        (\Pi n.\ P\ n \to P\ (\natsucc\ n)) \to
        \Pi n. P\ n
  \]
  There are ways to generate them automatically~\sidecite{kovacs2020signatures}
  and \Coq does it to some extent. The troublesome part is getting the
  right computation rules and dealing with nested inductive types.
  In this case, the computation rules are
  \[
    \begin{array}{lcl}
      \natrec\ P\ p_\zero\ p_\natsucc\ \zero &\red& p_\zero \\
      \natrec\ P\ p_\zero\ p_\natsucc\ (\natsucc\ n) &\red&
      p_\natsucc\ n\ (\natrec\ P\ p_\zero\ p_\natsucc\ n) \\
    \end{array}
  \]

  \item \emph{Fixed-points.} The method used in \Coq comes from a combination of
  pattern-matching and a fixed-point operator.
  \marginnote[0.7cm]{
    The notation \(\Pi \D. T\) is to quantify over a whole context.
    If \(\D\) is \(x : A, y : B\), \(\Pi \D. T\) is \(\Pi (x:A)\ (y:B).\ T\).
    When \(\D\) is empty, this is just \(T\).
  }
  \[
    \infer
      {
        \Ga \vdash \Pi \Delta. T \\
        \Ga, f : \Pi \Delta. T, \D \vdash t : T \\
        \highlight{f \vdash_n t \text{ termination checks}}
      }
      {\Ga \vdash \fixp_n (f : \Pi \Delta. T).\ t : \Pi \Delta. T}
    %
  \]
  The termination checking condition roughly verifies that the \(n\)-th argument
  in \(\D\) is only fed to \(f\) (\ie recursive calls) in a decreasing manner.
  This so-called guard condition is a complicated matter and out of scope of
  this thesis and probably better studied in
  \sidecite{gimenez1998structural,gimenez1994codifying}.
  In general this can be thought as only subterms of the argument are passed on
  to \(f\).
  The computational behaviour of the fixed-point operator is via unfolding of
  its definition.
  \[
    \fixp_n (f : \Pi \D.T).\ t \red
    \lambda \D.\ t[f \sto \fixp_n (f : \Pi \D.T).\ t]
  \]
  Of course, doing this would defeat the purpose of the termination checker:
  ensuring that the obtained definition terminates. As you can see you can
  unfold the fixed-point indefinitely.
  The way we prevent that is by using a syntactical guard on the reduction rule.
  It is instead the following.
  \marginnote[0.6cm]{
    \(\mathbf{C}\) stands for a constuctor like \(\zero\) or \(\natsucc\).
  }
  \[
    \begin{array}{lc}
      (\fixp_n (f : \Pi \D.T).\ t)\
      u_1\ \dots\ u_{n-1}\ (\mathbf{C}\ v_1\ \dots\ v_m)
      &\red \\
      (\lambda \D.\ t[f \sto \fixp_n (f : \Pi \D.T).\ t])\
      u_1\ \dots\ u_{n-1}\ (\mathbf{C}\ v_1\ \dots\ v_m)
    \end{array}
  \]
  We can then write down the induction principle \(\natrec\) with \(\fixp\)
  and \(\mathsf{match}\).
  \marginnote[2cm]{
    Notice how \(m\) is a subterm of \(\natsucc\ m\) in the recursive call to
    \(f\). It is indeed its fourth argument.
  }
  \[
    \begin{array}{l}
      \fixp_4\ (f : \Pi\ P\ p_\zero\ p_\natsucc\ n.\ P\ n). \\
      \pmatch{n}{x.\ P\ x}{
        \branch{\zero}{p_\zero} \\
        \branch
          {\natsucc\ m}
          {p_\natsucc\ m\ (f\ P\ p_\zero\ p_\natsucc\ \highlight{m})}
      }
    \end{array}
  \]
  It will have the same reduction rules as the eliminator shown above.
\end{itemize}

I won't go into that much detail for other inductive types as they will all
follow more or less the same schema.

\subsection{Parameterised inductive types}

Parameterised inductive types, as the name suggests, can take parameters.
In \ocaml, parameters are necessarily types, and it is often the case in \Coq
though everything goes.

\paradot{Lists}

I already presented lists in \ocaml, and their \Coq counterpart isn't much
different.
\begin{mathpar}
  \infer
    {\Ga \vdash A}
    {\Ga \vdash \tlist\ A}
  %

  \infer
    {\Ga \vdash A}
    {\Ga \vdash \nil : \tlist\ A}
  %

  \infer
    {
      \Ga \vdash A \\
      \Ga \vdash h : A \\
      \Ga \vdash t : \tlist\ A
    }
    {\Ga \vdash h :: t : \tlist\ A}
  %

  \infer
    {
      \Ga \vdash l : \tlist\ A \\
      \Ga, x : \tlist\ A \vdash P \\
      \Ga \vdash u_\nil : P[x \sto \nil] \\
      \Ga, h : A, t : \tlist\ A \vdash u_{::} : P[x \sto h :: t]
    }
    {
      \Ga \vdash
      \pmatch{l}{x.P}{
        \branch{\nil}{u_\nil} \\
        \branch{h :: t}{u_{::}}
      }
      : P[x \sto l]
    }
  %
\end{mathpar}
The computation rules are the ones you should expect by now.
Similarly to natural numbers, that can be combined with the fixed-point operator
to perform induction on lists, the type of which is
\[
  \Pi\ A\ (P : \tlist\ A \to \Type).\
  P\ \nil \to
  (\Pi\ h\ t.\ P\ t \to P\ (h :: t)) \to
  \Pi\ l.\ P\ l
\]

\paradot{Options}

\(\option\ A\) represents a potential data of type \(A\) but it could also not
be present. It is optional.
\begin{mathpar}
  \infer
    {\Ga \vdash A}
    {\Ga \vdash \option\ A}
  %

  \infer
    {\Ga \vdash a : A}
    {\Ga \vdash \some\ a : \option\ A}
  %

  \infer
    {\Ga \vdash A}
    {\Ga \vdash \none : \option\ A}
  %

  \infer
    {
      \Ga \vdash o : \option\ A \\
      \Ga, x : \option\ A \vdash P \\
      \Ga, a : A \vdash u_\some : P[x \sto \some\ a] \\
      \Ga \vdash u_\none : P[x \sto \none]
    }
    {
      \Ga \vdash
      \pmatch{o}{x.P}{
        \branch{\some\ a}{u_\some} \\
        \branch{\none}{u_\none}
      }
      : P[x \sto o]
    }
  %
\end{mathpar}
It is an easy way of representing functions that are not defined on their whole
domain (they return \(\none\) when they are not).

\paradot{Sum types}

Simple sums \(A + B\) consist in a disjunction of cases. A proof of \(A + B\)
is either a proof of \(A\) or a proof of \(B\).
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga \vdash B
    }
    {\Ga \vdash A + B}
  %

  \infer
    {
      \Ga \vdash a : A \\
      \Ga \vdash B
    }
    {\Ga \vdash \inl\ a : A + B}
  %

  \infer
    {
      \Ga \vdash b : B \\
      \Ga \vdash A
    }
    {\Ga \vdash \inr\ b : A + B}
  %

  \infer
    {
      \Ga \vdash p : A + B \\
      \Ga, x : A + B \vdash P \\
      \Ga, a : A \vdash u : P[x \sto \inl\ a] \\
      \Ga, b : B \vdash v : P[x \sto \inr\ b]
    }
    {
      \Ga \vdash
      \pmatch{p}{x.P}{
        \branch{\inl\ a}{u} \\
        \branch{\inr\ b}{v}
      }
      : P[x \sto p]
    }
  %
\end{mathpar}

\paradot{Simple products}

Simple products \(A \times B\) are types of pairs of elements, one in \(A\)
and one in \(B\). None too surprising.
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga \vdash B
    }
    {\Ga \vdash A \times B}
  %

  \infer
    {
      \Ga \vdash a : A \\
      \Ga \vdash b : B
    }
    {\Ga \vdash (a,b) : A \times B}
  %

  \infer
    {
      \Ga \vdash p : A \times B \\
      \Ga, x : A \times B \vdash P \\
      \Ga, a : A, b : B \vdash t : P[x \sto (a,b)]
    }
    {
      \Ga \vdash
      \pmatch{p}{x.P}{
        \branch{(a,b)}{t}
      }
      : P[x \sto p]
    }
  %
\end{mathpar}

This presentation of pairs is called \emph{positive} as it uses a constructor.
In the section on records I will show the \emph{negative} version.

\paradot{\(\Sigma\)-types}

\marginnote[0.2cm]{
  In the simple case we have sums \(A + B\), products \(A \times B\)
  and exponentials \(B^A\) or \(A \to B\). In the dependent case however, it is
  all shifted: we have sums \(\Sigma A.B\) and products \(\Pi A.B\).
}
Dependent sums or \(\Sigma\)-types are a generalisation of simple products to
dependent types. They are the way to represent existential quantifier
(except in a---usually---constructive way): \(\Sigma (x:A).P\ x\) is proven by
giving a term \(t : A\) and a proof of \(P\ t\).
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga, x : A \vdash B
    }
    {\Ga \vdash \Sigma (x:A). B}
  %

  \infer
    {
      \Ga, x:A \vdash B \\
      \Ga \vdash a : A \\
      \Ga \vdash b : B[x \sto a]
    }
    {\Ga \vdash \dpair{a,b} : \Sigma (x:A).B}
  %

  \infer
    {
      \Ga \vdash p : \Sigma (x:A).B \\
      \Ga, x : \Sigma (x:A).B \vdash P \\
      \Ga, a : A, b : B[x \sto a] \vdash t : P[x \sto \dpair{a,b}]
    }
    {
      \Ga \vdash
      \pmatch{p}{x.P}{
        \branch{\dpair{a,b}}{t}
      }
      : P[x \sto p]
    }
  %
\end{mathpar}
Once more, this is the \emph{positive} presentation of \(\Sigma\)-types.
With this presentation it is also possible to restrict \(P\) in case we don't
want to make it possible to extract the witness (the \(a\) in \(\dpair{a,b}\)).

\marginnote[0.2cm]{
  The \(\_\) is there to note that \(B\) does not depend on the variable in
  \(A\).
}
It is also worth noting that simple products are a particular case of
\(\Sigma\)-type: \(A \times B\) can be defined as \(\Sigma (\_:A).B\).

\subsection{Indexed inductive types}

\marginnote[1cm]{
  In all the examples I showed, the parameters are \emph{uniform}, \ie they are
  the same everywhere, but there can be non uniform occurrences of them where
  the recursive argument is at a different parameter.
}
Inductive types can have parameters, but they can also have \emph{indices}.
They are similar to parameters in that they are arguments to the inductive type
but while parameters are always the same in the \emph{conclusion} of the type of
a constructor, indices can vary.
I will show the two most talked about cases of indexed inductive types: vectors
and equality.

\paradot{Vectors}

Vectors are length-indexed lists: \(\tvec_A\ n\) is type of lists of length
\(n\) whose elements inhabit \(A\). In this case, \(A\) is a parameter and
\(n\) is an index.
\marginnote[1cm]{
  I highlight the index for the constructors to show how it differs.
  \(\vnil\) is the only list of length \(0\) and a \(\vcons\) always adds one
  element to a vector.
}
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga \vdash n : \nat
    }
    {\Ga \vdash \tvec_A\ n}
  %

  \infer
    {\Ga \vdash A}
    {\Ga \vdash \vnil : \tvec_A\ \highlight{\zero}}
  %

  \infer
    {
      \Ga \vdash a : A \\
      \Ga \vdash n : \nat \\
      \Ga \vdash v : \tvec_A\ n
    }
    {\Ga \vdash \vcons\ a\ n\ v : \tvec_A\ \highlight{\natsucc\ n}}
  %

  \infer
    {
      \Ga \vdash v : \tvec_A\ n \\
      \Ga, p : \nat, x : \tvec_A\ p \vdash P \\
      \Ga \vdash u_\vnil : P[p \sto 0, x \sto \vnil] \\
      \Ga, a : A, m : \nat, w : \tvec_A\ m \vdash
      u_\vcons : P[p \sto \natsucc\ m, x \sto \vcons\ a\ m\ w]
    }
    {
      \Ga \vdash
      \pmatch{v}{p.x.P}{
        \branch{\vnil}{u_\vnil} \\
        \branch{\vcons\ a\ m\ w}{u_\vcons}
      }
      : P[p \sto n, x \sto v]
    }
  %
\end{mathpar}
The pattern-matching this time binds \emph{two} variables: the variable
representing the matched term as usual, but also the index! This is because it
varies depending on the branch.

Vectors are pretty useful because since you account for the length, you can
write safer and more precise functions. For instance, the tail function on lists
would land in an option type (in the case the list is \(\nil\)), but here we
can easily say it should only take some \(\tvec_A\ (\natsucc\ n)\) as argument,
ruling out the empty vector completely.
\marginnote[1.4cm]{
  The return type is also more precise: the tail of a list of length
  \(\natsucc\ n\) is of length \(n\).
}
\[
  \begin{array}{l}
    \lambda\ A\ (n : \nat)\ (v : \tvec_A\ (\natsucc\ n)). \\
    \pmatch{v}{p.x. \tvec_A\ n}{
      \branch{\vcons\ a\ m\ w}{w}
    }
  \end{array}
\]
Notice how I didn't even provide a branch for \(\vnil\) because it will always
by ill-typed. This is unfortunately impossible in vanilla \Coq but is supported
in \Agda natively and can be achived in \Coq with \Program of the \Equations
plugin~\sidecite{DBLP:conf/itp/Sozeau10,sozeau2019equations}.
With the typing rules I gave it is still possible to do it, it's just that we
have to conclude using the elimination of \(\bot\) in the \(\vnil\) branch.

\paradot{Equality}
As equality is special I will only give a brief definition before we dicuss it
in more detail later in this chapter. In \nrefch{flavours} I will also show
different notions of equality.
In any case, we want the type \(u =_A v\) to represent equality of terms \(u\)
and \(v\) of type \(A\). When can you prove that \(u\) and \(v\) are
\emph{equal}? When they are the same!
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga \vdash u : A \\
      \Ga \vdash v : A
    }
    {\Ga \vdash u =_A v}
  %

  \infer
    {\Ga \vdash u : A}
    {\Ga \vdash \refl{A} u : u =_A u}
  %

  \infer
    {
      \Ga \vdash u : A \\
      \Ga \vdash v : A \\
      \Ga \vdash e : u =_A v \\
      \Ga, x : A, p : u =_A x \vdash P \\
      \Ga \vdash t : P[x \sto u, p \sto \refl{A} u]
    }
    {
      \Ga \vdash
      \pmatch{e}{x.p.P}{
        \branch{\refl{}}{t}
      }
      : P[x \sto v, p \sto e]
    }
  %
\end{mathpar}
\(\refl{A} u\) is the reflexivity proof and it \emph{unifies} \(u\) and \(v\)
in its return type. Hence you can conclude that \(v\) is an index while \(A\)
and \(u\) are parameters.
The pattern-matching in the case where \(P\) does not depend on the equality
\(p\) helps us recover Leibniz's principle stating that \(u = v\) means that
for every \(P\), \(P\ x \to P\ y\).
In particular this allows us to \emph{rewrite} equalities, \ie chaging something
for something else equal to it in an expression.

Generally speaking indices are complex to deal with and it is related to how
equality is complex in type theory, hence the multiple approaches there are to
it.

\subsection{Other inductive types}

There are other kinds of inductive types and I shall go briefly over some of
them.

\paradot{Mutual inductive types}

Sometimes you want to define two notions at the same time because they are
linked or interleaved.
Take the notion of odd and even numbers for instance. They can both be defined
independently or one built on top of the other, but they can also be defined
mutually: \(0\) is even, when \(n\) is even, \(n+1\) is odd and when \(n\)
is odd, \(n+1\) is even.
In \Coq it goes like this.
\begin{minted}{coq}
Inductive even : nat -> Type :=
| even_O : even 0
| even_S : forall n, odd n -> even (S n)

with odd : nat -> Type :=
| odd_S : forall n, even n -> odd (S n).
\end{minted}

To deal with them you need mutual fixed-points.

\paradot{Inductive inductive types and induction recursion}

\marginnote[0.7cm]{
  In the \emph{mutual} case, only the constructors could mention the other
  inductive types.
}
Pushing even further in that direction, come inductive inductive
types~\sidecite[1.3cm]{forsberg2010inductive} where the type of inductive types
can also depend on the other inductive types.
Induction recursion~\sidecite[1.2cm]{dybjer2000general} allows you to define
inductive types mutually with functions acting on them.

Both these features are not available in \Coq yet, but are present in \Agda.

\section{Coinductive types and records}

Not all data is best represented inductively, instead of constructors it is
possible to talk about \emph{destructors}, \ie observations.

\subsection{Records}

Records are datatypes containing different fields. In \Coq they can be defined
like this.
\begin{minted}{coq}
Record prod A B := pair {
  fst : A ;
  snd : B
}
\end{minted}
This corresponds to another way of defining \(A \times B\).

Historically in \Coq, records are defined as inductive types with one
constructor. The above definition is in fact syntactic sugar for
\begin{minted}{coq}
Inductive prod A B :=
| pair : A -> B -> prod A B.

Definition fst A B (p : prod A B) : A :=
  match p with
  | pair a b => a
  end.

Definition snd A B (p : prod A B) : B :=
  match p with
  | pair a b => b
  end.
\end{minted}
This is what we call \emph{positive} records, corresponding to the presentation
of \(A \times B\) and \(\Sigma (x:A).B\) I made earlier.

There is however an option in \Coq to instead use a \emph{negative}
presentation:
\begin{minted}{coq}
Set Primitive Projections.
\end{minted}
Once it is set the definition above of the record becomes primitive.
The constructor \mintinline{coq}{pair} is the one that becomes a definition:
\begin{minted}{coq}
Definition pair A B (a : A) (b : B) : prod A B :=
  {|
    fst := a ;
    snd := b
  |}.
\end{minted}

I will now give the typing rules of negative \(\Sigma\)-types.
\begin{mathpar}
  \infer
    {
      \Ga \vdash A \\
      \Ga, x : A \vdash B
    }
    {\Ga \vdash \Sigma (x:A). B}
  %

  \infer
    {\Ga \vdash p : \Sigma (x:A).B}
    {\Ga \vdash \pi_1\ p : A}
  %

  \infer
    {\Ga \vdash p : \Sigma (x:A).B}
    {\Ga \vdash \pi_2\ p : B[x \sto \pi_1\ p]}
  %

  \infer
    {
      \Ga \vdash a : A \\
      \Ga, x:A \vdash B \\
      \Ga \vdash b : B[x \sto a]
    }
    {\Ga \vdash \dpair{a,b} : \Sigma (x:A).B}
  %
\end{mathpar}

The way to think about them is that when providing \(\dpair{a,b}\) you are
actually saying how the term will behave when projected (by either \(\pi_1\)
and \(\pi_2\)).
This is illustrated by the computation rules.
\[
  \begin{array}{lcl}
    \pi_1\ \dpair{a,b} &\red& a \\
    \pi_2\ \dpair{a,b} &\red& b
  \end{array}
\]

I already hinted at this, but with this presentation it is not possible to
restrict usage of \(\pi_1\), it is always possible to recover the witness.

\subsection{Coinductive types}

Coinductive types are the dual of inductive types and are used to represent
potentially infinite data. Streams of data are one such example: like lists
streams have heads and tails, except there always is a tail, it is never-ending.
\begin{mathpar}
  \infer
    {\Ga \vdash A}
    {\Ga \vdash \stream\ A}
  %

  \infer
    {\Ga \vdash s : \stream\ A}
    {\Ga \vdash \head\ s : A}
  %

  \infer
    {\Ga \vdash s : \stream\ A}
    {\Ga \vdash \tail\ s : \stream\ A}
  %
\end{mathpar}
In the definition of the coinductive type of streams we define destructors:
\(\head\) and \(\tail\) are means to inspect a \(\stream\).
We cannot use constructors to describe a stream however as it is infinite.
There are several ways to build such data but the one I find most convincing and
beautiful is to use a dual approach to pattern-matching:
\emph{copattern-matching}~\sidecite{abel2013copatterns}, usually in combination
with co-fixed-point.
In \Agda, the stream consisting only of zeroes can be defined as follows:
\begin{minted}{agda}
zeroes : Stream Nat
head zeroes = zero
tail zeroes = zeroes
\end{minted}
while the stream of natural numbers starting at \(n\) is
\begin{minted}{agda}
seq : Nat â†’ Stream Nat
head (seq n) = n
tail (seq n) = seq (succ n)
\end{minted}
In won't go into further detail about those, coinductive types are not really
well-behaved in \Coq so we mostly ignore them for the time being.

\section{Equality}
\labsec{equality-def}

\reminder[-0.7cm]{Equality}{
  Equality is given by the following rules.
  \[
    \infer
      {
        \Ga \vdash A \\
        \Ga \vdash u : A \\
        \Ga \vdash v : A
      }
      {\Ga \vdash u =_A v}
    %
  \]
  \[
    \infer
      {\Ga \vdash u : A}
      {\Ga \vdash \refl{A} u : u =_A u}
    %
  \]
  \[
    \infer
      {
        \Ga \vdash u : A \\
        \Ga \vdash v : A \\
        \Ga \vdash e : u =_A v \\
        \Ga, x : A, p : u =_A x \vdash P \\
        \Ga \vdash t : P[x \sto u, p \sto \refl{A} u]
      }
      {
        \Ga \vdash
        \fitmatch{e}{x.p.P}{
          \fitbranch{\mathsf{refl}}{t}
        }
        : P[x \sto v, p \sto e]
      }
    %
  \]
}
I will here describe some usual definition and concepts associated with equality
in type theory, mostly from the point of view of \Coq.
Again, several notions of equality are of interest and I study them briefly
in \nrefch{flavours}.

\subsection{Basic properties of equality}

Equality, by all means, should be a congruence, and it is. It might be
surprising given that we \emph{only} ask for it to be reflexive.
Induction helps us recover these properties.

We can build a term \(\eqrec\) corresponding to the eliminator for equality.
\[
  \begin{array}{lcl}
    \eqrec &:&
    \Pi\ A\ (u : A)\ (P : \Pi\ (x : A).\ u =_A x \to \Type).\ \\
    && \quad P\ u\ (\refl{A}\ u) \to \\
    && \quad \Pi\ v\ (e : u =_A v).\ P\ v\ e
  \end{array}
\]
Its definition is
% eq_rect =
% fun (A : Type) (x : A) (P : A -> Type) (f : P x) (y : A) (e : x = y) =>
% match e in (_ = y0) return (P y0) with
% | eq_refl => f
% end
% 	 : forall (A : Type) (x : A) (P : A -> Type),
%        P x -> forall y : A, x = y -> P y
\[
  \begin{array}{l}
    \lambda\ A\ u\ P\ t\ v\ e.\ \\
    \pmatch{e}{x.p.\ P\ x\ p}{
      \branch{\refl{}}{t}
    }
  \end{array}
\]

\subsection{Independent principles}

\todo{This is not a debate about how to define it, we will show the Coq one
and refer to the next chapter to the discussion about its definition.}
\todo{UIP, funext, transport, heterogenous equality}

\acrfull{JMeq} introduced by
\sidecite{mcbride2000dependently} has axioms
instead better
\[ \Heq{T}{t}{U}{u} := \Sum{p:\Eq{}{T}{U}} \Eq{}{\transpo{p}\ t}{u}. \]