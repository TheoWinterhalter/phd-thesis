% \setchapterpreamble[u]{\margintoc}
\chapter{Conversion}
\labch{coq-conversion}

We want to implement a correct conversion checker that is close enough to the
actual implementation that is rather efficient, instead of the naive solution
of reducing both terms to normal forms and then comparing them syntactically.
We also have to take care of universes and cumulativity which complicates matter
a little bit.

\section{High level description}

I will present our approach at the high level.
\begin{enumerate}[label=(\arabic*)]
  \item \label{itm:convred} First we weak head reduce the two terms without
  \(\delta\)-reduction (\ie without unfolding definitions);
  \item then we compare their heads, if they match we begin again at
  \ref{itm:convred};
  \item if they do not match, we check if some computation (pattern-matching
  or fixed-point)---or even the whole term---is blocked by a definition that
  could unfold to a value, and if so we unfold the definition and start again.
\end{enumerate}

Following reduction, we actually use terms versus stacks to deal with focusing.
Conversion is in fact split in four main phases that I codify as follows
\begin{itemize}
  \item \mintinline{coq}{Reduction} which corresponds to putting the two terms
  in weak head normal forms;
  \item \mintinline{coq}{Term} which corresponds to comparing the heads of the
  focused terms;
  \item \mintinline{coq}{Args} which corresponds to comparing the arguments
  on the stacks;
  \item \mintinline{coq}{Fallback} which happens when comparing different heads
  and we attempt to reduce both sides a bit more.
\end{itemize}
These roughly correspond each to one of the mutual definitions that yield
conversion. I will write these functions as judgements:
\marginnote[0.5cm]{
  Here I forget about the typing requirements, but conversion, like reduction,
  can only operate on well-typed terms.
}
\[
  \begin{array}{c}
    \isconv{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}
  \end{array}
\]
where \(A\) is the \emph{answer} which is basically `yes' or an error message.
\(A\) is the \emph{output} while everything else is the \emph{input}.
I will use the subscripts \(\cred\), \(\cterm\), \(\cargs\) and \(\cfall\)
to diffrenciate the four phases.
I will present them in more depth so that we can see what are
the requirements for termination.

\subsection{\mintinline{coq}{Reduction}}

The first phase takes two pairs of term and stack and reduce both using the
weak head reduction machine of \nrefch{coq-reduction}.
In order to avoid unfolding definitions unnecessarily, we disable the
\(\delta\)-reduction.
% This means that we pass the
% \begin{minted}{coq}
% RedFlags.nodelta
% \end{minted}
% flags to the machine.
This means that we pass the \mintinline{coq}{RedFlags.nodelta} flags to the
machine.

I will once again describe these functions and their recursive calls using
inference rules for simplicity.
\begin{mathpar}
  \infer
    {
      \Ga \vdash \vscmd{t_1}{\pi_1} \red_{\WM \not\delta} \vscmd{u_1}{\rho_1} \\
      \Ga \vdash \vscmd{t_2}{\pi_2} \red_{\WM \not\delta} \vscmd{u_2}{\rho_2} \\
      \convterm{\Ga}{u_1}{\rho_1}{u_2}{\rho_2}{A}
    }
    {\convred{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}}
  %
\end{mathpar}
Here we simply do a recursive call on the weak head normal forms of the two
inputs.

\subsection{\mintinline{coq}{Term}}

For this phase, we take two inputs that are in weak head normal form (without
\(\delta\)-reduction) and look at the heads of the terms.
The idea behind disabling \(\delta\) is that when comparing two constants
we hope not to have to unfold them if they already are the same.
\[
  \infer
    {
      u_1 \cong u_2 \\
      \convargs{\Ga}{\const\ k\ u_1}{\pi_1}{\const\ k\ u_2}{\pi_2}{\ayes}
    }
    {\convterm{\Ga}{\const\ k\ u_1}{\pi_1}{\const\ k\ u_2}{\pi_2}{\ayes}}
  %
\]
where \(\const\ k\ u\) refers to the constant of name \(k\) and universe
instance \(u\).
Here we first compare the universe instances to check that they are equal
(which is a bit more general that syntactic equality), and if so we compare
the stacks, or more specifically the arguments on those. I will explain this
part when presenting the corresponding function.
\marginnote[0.1cm]{
  One or the two of them might refer to axioms and in that case, we only unfold
  those that can be, and if we compare two axioms, we know they are distinct.
}
If the constant names are not the same, or if the universe instances do not match
or if the argument comparison fails, we then unfold one of the constants and
compare them again.
\marginnote[1cm]{
  I informally write \(t_2[u_2]\) to mean \(t_2\) instantiated by \(u_2\).
}
\[
  \infer
    {
      (k_2 := t_2) \in \Sigma \\
      \convred{\Ga}{\const\ k_1\ u_1}{\pi_1}{t_2[u_2]}{\pi_2}{A}
    }
    {\convterm{\Ga}{\const\ k_1\ u_1}{\pi_1}{\const\ k_2\ u_2}{\pi_2}{A}}
  %
\]

Another interesting case is the comparison of \(\lambda\)-abstractions.
\marginnote[1cm]{
  Once again I show the rule when there are successes in each recursive calls,
  all the others yield errors.
}
\[
  \infer
    {
      \convred
        {\Ga}
        {A_1}
        {\stack{\lambda (x:\shole).\ t_1} :: \pi_1}
        {A_2}
        {\stack{\lambda (x:\shole).\ t_2} :: \pi_2}
        {\ayes}
      \\
      \convred
        {\Ga}
        {t_1}
        {\stack{\lambda (x:A_1).\ \shole} :: \pi_1}
        {t_2}
        {\stack{\lambda (x:A_2).\ \shole} :: \pi_2}
        {A}
    }
    {
      \convterm
        {\Ga}
        {\lambda (x:A_1).\ t_1}{\pi_1}
        {\lambda (x:A_2).\ t_2}{\pi_2}
        {A}
    }
  %
\]
First we compare the two domains and then we compare the two bodies.
This may seem like a simple case of recursing in the subterms but there is a
subtlety: the context when comparing the bodies is still \(\Ga\) and not
\(\Ga, x:A_1\) or \(\Ga, x:A_2\).
\marginnote[0.1cm]{
  A \emph{good} things that helps us complete proofs.
}
This is actually a good thing that we do not have to pick one of them and remain
symmetric.
We are saved by the stacks once more. Indeed, in
\(\stack{\lambda (x:A_1).\ \shole}\) we have the information corresponding to
\(x : A_1\). More generally, stacks do not only yield positions but also
contexts. In the expression
\[
  \isconv{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}
\]
\(t_1\) lives in \(\Ga, \stackctx\ \pi_1\), and \(t_2\) in
\(\Ga, \stackctx\ \pi_2\).

Other than those, we also deal with \(\Pi\)-types, pattern-matching,
projections, fixed- and cofixed-points.
The case of two applications is imposibble because the arguments would have been
pushed on the stacks.
If the terms do not fall in this diagonal, we instead call the fallback
function recursively.
\[
  \infer
    {\convfall{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}}
    {\convterm{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}}
  %
\]

\subsection{\mintinline{coq}{Args}}

When the two terms are convertible, it is time to move on the comparison of the
stacks, or rather the comparision of the leading arguments on said stacks.

A stack \(\pi\) can be decomposed into a list of arguments \(u_1, \dots, u_n\)
and a remaining stack \(\rho\) that does not start with some \(\coapp{u}\),
such that
\[
  \pi = \coapp{u_1} :: \dots :: \coapp{u_n} :: \rho
\]
With two such decomposed stacks, the meaning of the \mintinline{coq}{Args}
function is the following
\marginnote[1cm]{
  Notice how we have \(n\) arguments on both sides, if there is a mismatch,
  the function will return an error.
}
\[
  \footnotesize
  \infer
    {
      \convred
        {\Ga}
        {u_1}
        {\stack{t_1\ \shole\ u_2\ \dots u_n} :: \rho_1}
        {v_1}
        {\stack{t_2\ \shole\ v_2\ \dots v_n} :: \rho_2}
        {\ayes}
      \\\\
      \vdots \\\\
      \convred
        {\Ga}
        {u_n}
        {\stack{t_1\ u_1\ \dots u_{n-1}\ \shole} :: \rho_1}
        {v_n}
        {\stack{t_2\ v_1\ \dots v_{n-1}\ \shole} :: \rho_2}
        {\ayes}
    }
    {
      \convargs
        {\Ga}
        {t_1}
        {\coapp{u_1} :: \dots :: \coapp{u_n} :: \rho_1}
        {t_2}
        {\coapp{v_1} :: \dots :: \coapp{v_n} :: \rho_2}
        {A}
    }
  %
\]
Assuming that \(\Ga \vdash u_1 \equiv u_2\), it saying `yes' means that
\[
  \Ga \vdash t_1\ u_1\ \dots\ u_n \equiv t_2\ v_1\ \dots\ v_n
\]
(and also the stronger property that each \(u_i\) is convertible to \(v_i\) but
the property above is sufficient for our needs).

\subsection{\mintinline{coq}{Fallback}}

The fallback deals with terms outside of the diagonal that are potentially
stuck because of definitions that are not unfolded.
It tries to make progress on each side before resorting to plain and simple
syntactic equality.
\marginnote[1cm]{
  I use \(\red_\WM \not =\) to mean that the reduction produced a different term.
  In the formalisation its a different process that checks that the term is
  indeed stuck because of \(\delta\).
}
\marginnote[4.4cm]{
  Here \(t_1 = t_2\) means that \(t_1\) and \(t_2\) have been checked to be
  syntactically equal, up to universes.
}
\begin{mathpar}
  \infer
    {
      \Ga \vdash \vscmd{t_1}{\pi_1} \red_\WM \not= \vscmd{u}{\rho} \\
      \convterm{\Ga}{u}{\rho}{t_2}{\pi_2}{A}
    }
    {\convfall{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}}
  %

  \infer
    {
      \Ga \vdash \vscmd{t_2}{\pi_2} \red_\WM \not= \vscmd{u}{\rho} \\
      \convterm{\Ga}{t_1}{\pi_1}{u}{\rho}{A}
    }
    {\convfall{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}}
  %

  \infer
    {
      t_1 = t_2 \\
      \convargs{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}
    }
    {\convfall{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}}
  %
\end{mathpar}

\subsection{About cumulativity and universes}

In the (partial) definitions above I sometimes refer to syntactic equality of
terms or equality of universes. These are alaways refering to the universe
constraints to be decided, \ie their respective representations need not be the
same on both sides of the equality. This is the reason why I write \(u = v\)
when I could have unified them, the way I unified \(k_1\) and \(k_2\) into \(k\)
when considering constants.

Another important point is that we actually define conversion and cumulativity
at the same time, using an extra argument (essentially a boolean) telling us
which of those we are checking for.
I did everything in the setting of conversion to have lighter notations, but
everything works just as well with cumulativity.

I will not explain how we specify and check equality or cumulativity of
universes as it was not my own contribution.
The interested reader should refer either to~\sidecite{sozeau2019coq} or the
formalisation.

\section{Termination and correctness}

\subsection{Specification}

You will perhaps find my presentation surprising in that I did not even specify
what was expected of the algorithm I was showing. I wanted to focus on the
intuition before going into these details.
It is time to correct this slight.

All the `judgements' I presented earlier, that is
\[
  \begin{array}{l}
    \convred{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A} \\
    \convterm{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A} \\
    \convargs{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A} \\
    \convfall{\Ga}{t_1}{\pi_1}{t_2}{\pi_2}{A}
  \end{array}
\]
are correct if, when they return \(\ayes\), we have
\[
  \Ga \vdash t_1\ u_1\ \dots\ u_n \equiv t_2\ v_1\ \dots\ v_n
\]
where \(\pi_1\) and \(\pi_2\) are decomposed as
\[
  \begin{array}{rcl}
    \pi_1 &=& \coapp{u_1} :: \dots :: \coapp{u_n} :: \rho_1 \\
    \pi_2 &=& \coapp{v_1} :: \dots :: \coapp{v_n} :: \rho_2
  \end{array}
\]
This might be a bit surprising that we only conclude on applications at the head
of the stakcs and not about the whole stacks themselves.
If we were asking for
\[
  \Ga \vdash \zip\ \vscmd{t_1}{\pi_1} \equiv \vscmd{t_2}{\pi_2}
\]
instead, it would be too strong a requirement. Indeed, in the case of
\(\lambda\)-abstractions, we consider the recrusive call on the domains
\marginnote[1cm]{
  Note that \(\zip\ \vscmd{A}{\stack{\lambda (x:\shole).t} :: \pi}\)
  is equal to \(\zip\ \vscmd{\lambda (x:A).t}{\pi}\).
}
\[
  \convred
    {\Ga}
    {A_1}
    {\stack{\lambda (x:\shole).\ t_1} :: \pi_1}
    {A_2}
    {\stack{\lambda (x:\shole).\ t_2} :: \pi_2}
    {\ayes}
\]
which we want to conclude on \(A_1\) and \(A_2\), not on the full term,
otherwise the recusrive call on the bodies becomes superfluous.
This, I think, is a sign, that this approach is doomed to fail.

Going back to the bigger picture, it is also not a problem that we conclude only
on a portion of the stack since the conversion algorithm will be called with
empty stacks at the start.
\marginnote[0.8cm]{
  As you can see we also call the \mintinline{coq}{Reduction} phase first as
  well.
}
\[
  \convred{\Ga}{t_1}{\varepsilon}{t_2}{\varepsilon}{A}
\]

We can now move on to the main difficulty regarding conversion: its termination.

\subsection{Termination}

You can see that the definition of the conversion algorithm is reminiscent of
that of weak head reduction, and one might expect the termination orders to be
relatively close. This is indeed the case, but things are slightly more
complicated here, mainly for two reasons: we sometimes consider terms up to
universes; and we have mutually defined functions.

I will go over the different kind of recursive calls to motivate the order,
before introducing it.

The first rule I presented involves putting both terms in weak head normal
form before recursing on them. As we know from the correctness of weak head
reduction, the terms it yields are reducts of the orginal terms, and some
focusing potentially happened. As such, the order used by reduction seems like
a good option, save for one problem: in some cases---when the term is already
in weak head normal form---the weak reduction returns the original term.
Because of this, the phases must be part of the order.
In particular we want to have
\[
  \cterm \prec \cred
\]

Similarly, when comparing constants in the \mintinline{coq}{Term} phase,
we have a recursive call to the \mintinline{coq}{Args} phase with the same
arguments so we also want
\[
  \cargs \prec \cterm
\]
When we unfold one of the constants however, we go back from the
\mintinline{coq}{Term} phase to the \mintinline{coq}{Reduction} phase
so we really have to account for the fact that the unfolded definition is a
reduct of the constant, and it has to come before in the lexicographical
order.

The case of \(\lambda\)-abstractions tells us that similarly, the subterm
relation should come before the phase relation.

The \mintinline{coq}{Fallback} phase also happens with the same arguments as
that of the \mintinline{coq}{Term} phase so
\[
  \cfall \prec \cterm
\]

The \mintinline{coq}{Args} phase makes recrusive calls inside the stack meaning
that, like weak head reduction, we must in fact use positions rather than the
subterm relation.

Finally, the \mintinline{coq}{Fallback} phase can make recursive calls on the
\mintinline{coq}{Args} phase with the same arguments, meaning
\[
  \cargs \prec \cfall
\]

\paradot{The order}

Let me now introduce the order that we use to prove conversion terminating.
First we need to define the notion of phases (that I call states in the
formalisation):
\begin{minted}{coq}
Inductive state :=
| Reduction
| Term
| Args
| Fallback.
\end{minted}
as well as a well-founded order on them
\marginnote[0.3cm]{
  It should not prove to hard to see that it is indeed well-founded since we
  essentially have
  \[
    \cargs \prec \cfall \prec \cterm \prec \cred
  \]
}
\begin{minted}{coq}
Inductive stateR : state -> state -> Prop :=
| stateR_Term_Reduction : stateR Term     Reduction
| stateR_Args_Term      : stateR Args     Term
| stateR_Fallback_Term  : stateR Fallback Term
| stateR_Args_Fallback  : stateR Args     Fallback.
\end{minted}

I already said we needed to consider equality of terms up to universes, as such
we define an altered version of coreduction that is coreduction up to universes.
\marginnote[0.6cm]{
  The notation \mintinline{coq}{∥ A ∥} is for the \emph{squashed} version of
  \mintinline{coq}{A}, \ie its plunging into \mintinline{coq}{Prop}.
  This is to make sure it goes away after extraction.
}
\begin{minted}{coq}
Notation eqt u v :=
  (∥ eq_term (global_ext_constraints Σ) u v ∥).

Definition cored' Γ u v :=
  exists u' v', cored Σ Γ u' v' /\ eqt u u' /\ eqt v v'.
\end{minted}

\marginnote[2cm]{
  \mintinline{coq}{` w} is the first projection of \mintinline{coq}{w}, \ie
  a term, forgetting about its well-formedness proof.
}
Because coreduction is only well-founded for well-formed terms, I also define
the type of well-formed terms and coreduction on them.
\begin{minted}{coq}
Definition wterm Γ :=
  { t : term | wellformed Σ Γ t }.

Definition wcored Γ (u v : wterm Γ) :=
  cored' Σ Γ (` u) (` v).

Definition weqt {Γ} (u v : wterm Γ) :=
  eqt (` u) (` v).
\end{minted}

We can finally move on to the definition of the (auxiliary) order:
\marginnote[0.6cm]{
  Here I use \Equations which allows me to leave the coercions blank and provide
  them using tactics.
}
\begin{minted}{coq}
Equations R_aux (Γ : context) :
  (∑ t : term, pos t × (∑ w : wterm Γ, pos (` w) × state)) ->
  (∑ t : term, pos t × (∑ w : wterm Γ, pos (` w) × state)) ->
  Prop :=
  R_aux Γ :=
    t ⊨ eqt \ cored' Σ Γ by _ ⨷
    @posR t ⊗
    w ⊨ weqt \ wcored Γ by _ ⨷
    @posR (` w) ⊗
    stateR.
\end{minted}
So what we have here are nested dependent lexicographical orders modulo
syntactical equality up to universes.
The order operates on a term, a position in it, another term and position, and
finally a state, using coreduction for terms.

The real order simply repacks this information, computing the positions from
the stacks.
\begin{minted}{coq}
Record pack (Γ : context) := mkpack {
  st   : state ;
  tm1  : term ;
  stk1 : stack ;
  tm2  : term ;
  stk2 : stack ;
  wth  : wtp Γ tm2 stk2
}.

Arguments st {_} _.
Arguments tm1 {_} _.
Arguments stk1 {_} _.
Arguments tm2 {_} _.
Arguments stk2 {_} _.
Arguments wth {_} _.

Notation pzt u := (zipc (tm1 u) (stk1 u)) (only parsing).
Notation pps1 u := (stack_pos (tm1 u) (stk1 u)) (only parsing).
Notation pwt u := (exist _ (wth u)) (only parsing).
Notation pps2 u := (stack_pos (tm2 u) (stk2 u)) (only parsing).

Notation obpack u :=
  (pzt u ; (pps1 u, (pwt u ; (pps2 u, st u)))) (only parsing).

Definition R Γ (u v : pack Γ) :=
  R_aux Γ (obpack u) (obpack v).
\end{minted}

The order is well-founded and sufficient to prove termination of the conversion
algorithm which is also correct by construction.
In the end we get a conversion checker that operates on well-formed terms and
is proven sound:
\begin{minted}{coq}
Theorem isconv_term_sound :
  forall Γ leq t1 h1 t2 h2,
    isconv_term Γ leq t1 h1 t2 h2 = Success I ->
    conv_cum leq Σ Γ t1 t2.
\end{minted}
where \mintinline{coq}{leq} is the flag saying whether we compare for
cumulativity or conversion, and \mintinline{coq}{conv_cum leq} is either
cumulativity or conversion.

\section{Future work: \(\eta\)-conversion}

In the \Coq implementation, \(\eta\)-expansion is handled even though the
conversion is untyped. The way this is achieved is by only expanding a term
(which is not a \(\lambda\)-abstraction) when it is compared to a
\(\lambda\)-abstraction.
\[
  \infer
    {\convterm{\Ga}{\lambda (x:A).\ t_1\ x}{\pi_1}{\lambda (x:A).\ u}{\pi_2}{A}}
    {\convterm{\Ga}{t_1}{\pi_1}{\lambda (x:A).\ u}{\pi_2}{A}}
  %
\]
The recursive call would thus be followed by the congruence rule for
\(\lambda\)-abstractions.
For termination purposes this step is actually skipped and we directly do
\marginnote[1cm]{
  We also take advantage of this to skip the comparison of the domains since
  they are both necessarily the same.
}
\[
  \infer
    {
      \convred
        {\Ga}
        {t_1\ x}
        {\stack{\lambda (x:A).\ \shole} :: \pi_1}
        {u}
        {\stack{\lambda (x:A).\ \shole} :: \pi_2}
        {A}
    }
    {\convterm{\Ga}{t_1}{\pi_1}{\lambda (x:A).\ u}{\pi_2}{A}}
  %
\]

In our setting however, we would need to have the order not only modulo
universes but also modulo \(\eta\), and I have not yet managed to find a way
to account for \(\eta\) in a way that preserves well-foundedness.
As unfortunate as it is---it gets in the way of actually using our typechecker
on real-life examples---it will have to be future work for us.